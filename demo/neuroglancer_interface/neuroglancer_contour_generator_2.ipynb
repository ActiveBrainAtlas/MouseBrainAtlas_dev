{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Precision WorkStation for Alex Newberry\n",
      "{'MD589': 0.46, 'MD585': 0.46, 'UCSD001': 0.325}\n",
      "/media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/MD585/MD585_cropbox.ini\n",
      "/media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/MD585/MD585_cropbox.ini\n",
      "/media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/UCSD001/UCSD001_cropbox.ini\n",
      "/media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/UCSD001/UCSD001_cropbox.ini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seems you are using operation INIs to provide cropbox.\n",
      "Seems you are using operation INIs to provide cropbox.\n",
      "Seems you are using operation INIs to provide cropbox.\n",
      "Seems you are using operation INIs to provide cropbox.\n",
      "No anchor.txt is found. Seems we are using the operation ini to provide anchor. Try to load operation ini.\n",
      "Failed to cache DK1-2 anchor: ini file /media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/DK1-2/operation_configs/from_none_to_aligned.ini does not exist.\n",
      "File does not exist: /media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/DK1-2/DK1-2_sorted_filenames.txt\n",
      "Failed to cache DK1-2 sections_to_filenames: \n",
      "File does not exist: /media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/DK1-2/DK1-2_sorted_filenames.txt\n",
      "Failed to cache DK1-2 filenames_to_sections: \n",
      "No anchor.txt is found. Seems we are using the operation ini to provide anchor. Try to load operation ini.\n",
      "Failed to cache DK1-2 section_limits: ini file /media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/DK1-2/operation_configs/from_none_to_aligned.ini does not exist.\n",
      "No anchor.txt is found. Seems we are using the operation ini to provide anchor. Try to load operation ini.\n",
      "Failed to cache DK1-2 cropbox: ini file /media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/DK1-2/operation_configs/from_none_to_aligned.ini does not exist.\n",
      "Failed to cache DK1-2 valid_sections/filenames: DK1-2\n",
      "No anchor.txt is found. Seems we are using the operation ini to provide anchor. Try to load operation ini.\n",
      "Failed to cache DK1-2 image_shape: ini file /media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/DK1-2/operation_configs/from_none_to_aligned.ini does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from registration_utilities import *\n",
    "from annotation_utilities import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import neuroglancer\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running visualize_registration.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS RUNS visualize_registration_DEV.py\n",
    "stack = 'MD585'\n",
    "\n",
    "fn = stack+'_visualization_global_alignment_spec.json'\n",
    "data = {}\n",
    "\n",
    "data[\"stack_m\"] ={\n",
    "        \"name\":\"atlasV7\",\n",
    "        \"vol_type\": \"score\",\n",
    "        \"resolution\":\"10.0um\"\n",
    "        }\n",
    "data[\"stack_f\"] ={\n",
    "    \"name\":stack, \n",
    "    \"vol_type\": \"score\", \n",
    "    \"resolution\":\"10.0um\",\n",
    "    \"detector_id\":19\n",
    "    }\n",
    "data[\"warp_setting\"] = 0\n",
    "\n",
    "with open(fn, 'w') as outfile:\n",
    "    json.dump(data, outfile)\n",
    "\n",
    "# Reads data from:\n",
    "#   demo_visualization_per_structure_alignment_spec.json\n",
    "#   demo_visualization_global_alignment_spec.json\n",
    "\n",
    "fn_vis_structures = stack+'_visualization_per_structure_alignment_spec.json'\n",
    "fn_vis_global = stack+'_visualization_global_alignment_spec.json'\n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "# If Ntb\n",
    "# ! python visualize_registration.py NtbNormalizedAdaptiveInvertedGamma \\\n",
    "# demo_visualization_per_structure_alignment_spec.json \\\n",
    "# -g demo_visualization_global_alignment_spec.json\n",
    "# If Thionin\n",
    "# ! python visualize_registration_DEV.py grayJpeg $fn_vis_structures -g $fn_vis_global\n",
    "\n",
    "# print('Took ',time.time()-start_time, 'Seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Load SimpleGlobal and Local Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_contour_generator( stack, structure, use_local_alignment = True, image_prep = 2, threshold=0.5):\n",
    "\n",
    "    if use_local_alignment:\n",
    "        # Load local transformed volumes\n",
    "        str_alignment_spec = load_json(os.environ['REPO_DIR']+'../demo/'+fn_vis_structures)[structure]\n",
    "        vol = DataManager.load_transformed_volume_v2(alignment_spec = str_alignment_spec, \n",
    "                                                        return_origin_instead_of_bbox = True,\n",
    "                                                       structure = structure)\n",
    "    else:\n",
    "        # Load simple global volumes\n",
    "        str_alignment_spec = load_json(os.environ['REPO_DIR']+'../demo/'+fn_vis_global)\n",
    "        vol = DataManager.load_transformed_volume_v2(alignment_spec = global_alignment_spec, \n",
    "                                                                     return_origin_instead_of_bbox = True,\n",
    "                                                                    structure = structure)\n",
    "\n",
    "\n",
    "    # Load collection of bounding boxes for every structure\n",
    "    registered_atlas_structures_wrt_wholebrainXYcropped_xysecTwoCorners = \\\n",
    "            load_json(os.path.join(ROOT_DIR, 'CSHL_simple_global_registration', \\\n",
    "                                    stack + '_registered_atlas_structures_wrt_wholebrainXYcropped_xysecTwoCorners.json'))\n",
    "    # Load cropping box for structure. Only need the valid min and max sections though\n",
    "    (_, _, secmin), (_, _, secmax) = registered_atlas_structures_wrt_wholebrainXYcropped_xysecTwoCorners[structure]\n",
    "    # Load range of sections for particular structure\n",
    "    valid_secmin = 1\n",
    "    valid_secmax = 999\n",
    "    section_margin = 50 # 1000um margin / 20um per slice\n",
    "    atlas_structures_wrt_wholebrainWithMargin_sections = \\\n",
    "        range(max(secmin - section_margin, valid_secmin), min(secmax + 1 + section_margin, valid_secmax))\n",
    "\n",
    "    # Choose thresholds for probability volumes\n",
    "    levels = [threshold, 0.9]\n",
    "\n",
    "\n",
    "    # LOAD CONTOURS FROM VOLUME (function defined below)\n",
    "    str_contour = get_structure_contours_from_structure_volumes_v3(volumes={structure: vol}, stack=stack, \n",
    "                                                         sections=atlas_structures_wrt_wholebrainWithMargin_sections,\n",
    "                                                        resolution='10.0um', level=levels, sample_every=5)\n",
    "\n",
    "    # Check number sections that the contours are present on \n",
    "    str_keys = str_contour.keys()\n",
    "    valid_sections = []\n",
    "\n",
    "    for key in str_keys:\n",
    "        if isinstance(key,int) and key>1:\n",
    "            valid_sections.append(key)\n",
    "            # Need to check individual \"levels\" are on this section as well. \n",
    "            #    (0.1 threshold spans more slices than 0.9)\n",
    "    valid_sections.sort()\n",
    "    print 'Number of valid sections:'\n",
    "    num_valid_sections = len(valid_sections)\n",
    "    print num_valid_sections\n",
    "    first_sec = valid_sections[0]\n",
    "    last_sec = valid_sections[len(valid_sections)-1]\n",
    "    print 'First valid section:',first_sec\n",
    "    print 'Last valid section:',last_sec\n",
    "    print 'num_valid_sections:',num_valid_sections\n",
    "    print '\\n\\n'\n",
    "\n",
    "    #print str_contour[ valid_sections[0] ][structure][ levels[0] ]\n",
    "\n",
    "\n",
    "\n",
    "    # LOAD prep5->prep2 cropbox\n",
    "    if image_prep==5:\n",
    "        # wholeslice_to_brainstem = -from_padded_to_wholeslice, from_padded_to_brainstem\n",
    "        ini_fp = os.environ['DATA_ROOTDIR']+'CSHL_data_processed/'+stack+'/operation_configs/from_padded_to_brainstem.ini'\n",
    "        with open(ini_fp,'r') as fn:\n",
    "            contents_list = fn.read().split('\\n')\n",
    "        for line in contents_list:\n",
    "            if 'rostral_limit' in line:\n",
    "                rostral_limit = int( line.split(' ')[2] )\n",
    "            if 'dorsal_limit' in line:\n",
    "                dorsal_limit = int( line.split(' ')[2] )\n",
    "        ini_fp = os.environ['DATA_ROOTDIR']+'CSHL_data_processed/'+stack+'/operation_configs/from_padded_to_wholeslice.ini'\n",
    "        with open(ini_fp,'r') as fn:\n",
    "            contents_list = fn.read().split('\\n')\n",
    "        for line in contents_list:\n",
    "            if 'rostral_limit' in line:\n",
    "                rostral_limit = rostral_limit - int( line.split(' ')[2] )\n",
    "            if 'dorsal_limit' in line:\n",
    "                dorsal_limit = dorsal_limit - int( line.split(' ')[2] )\n",
    "#         rostral_limit = rostral_limit\n",
    "#         dorsal_limit = dorsal_limit\n",
    "        # DONE LOADING PREP5 OFFSETS\n",
    "    elif image_prep==2:\n",
    "        rostral_limit = 0\n",
    "        dorsal_limit = 0\n",
    "\n",
    "    # PLOT Contours\n",
    "    contour_str = str_contour[ valid_sections[num_valid_sections/2] ][structure][ levels[0] ]\n",
    "    # Downsample\n",
    "    y_len, x_len = np.shape(contour_str)\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for y in range(y_len):\n",
    "        x_list.append(rostral_limit + contour_str[y][0]/32)\n",
    "        y_list.append(dorsal_limit + contour_str[y][1]/32)\n",
    "\n",
    "    # PLOT Structure overlayed on thumbnail image\n",
    "    sorted_fns = DataManager.load_sorted_filenames(stack=stack)[0].keys()\n",
    "    # fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=5, resol='thumbnail', version='gray', fn=sorted_fns[int(len(sorted_fns)/2)])\n",
    "    img_fn = metadata_cache['sections_to_filenames'][stack][last_sec-num_valid_sections/2]\n",
    "    fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=image_prep, resol='thumbnail', version='gray', fn=img_fn)\n",
    "    \n",
    "#     img = imread(fp)\n",
    "#     plt.imshow( img, cmap='gray' )\n",
    "#     plt.scatter(x_list,y_list,s=1, color='r')\n",
    "#     plt.show()\n",
    "    \n",
    "    return str_contour, first_sec, last_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For current MD585 stack on neuroglancer\n",
    "ng_section_min = 83\n",
    "ng_section_max = 536\n",
    "ng_total_sections = 268 # 536 voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/alexn/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/MD585/MD585_cropbox.ini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seems you are using operation INIs to provide cropbox.\n",
      "2 contours of reconstructed volume is found at position 10 ([11, 1]). Use the longest one.\n",
      "2 contours of reconstructed volume is found at position 12 ([38, 1]). Use the longest one.\n",
      "2 contours of reconstructed volume is found at position 88 ([19, 1]). Use the longest one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid sections:\n",
      "46\n",
      "First valid section: 178\n",
      "Last valid section: 223\n",
      "num_valid_sections: 46\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stack = 'MD585'\n",
    "structure = '12N'\n",
    "threshold=0.1\n",
    "\n",
    "str_contour, first_sec, last_sec = image_contour_generator( stack, structure, use_local_alignment=True, image_prep=2, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_radius = 3\n",
    "\n",
    "\n",
    "# Max and Min X/Y Values given random initial values that will be raplaced\n",
    "# X and Y resolution will be 10um x 10um\n",
    "max_x = 0\n",
    "max_y = 0\n",
    "min_x = 9999999\n",
    "min_y = 9999999\n",
    "# 'min_z' is the relative starting section (if the prep2 sections start at slice 100, and the structure starts at slice 110, min_z is 10 )\n",
    "# Z resolution is 20um for simple 1-1 correspondance with section thickness\n",
    "max_z = (last_sec-ng_section_min)\n",
    "min_z = (first_sec-ng_section_min)\n",
    "# Scaling factor is (0.46/10). Scaling from resolution of 0.46 microns to 10 microns. \n",
    "scale_xy = 0.046\n",
    "\n",
    "# X,Y are 10um voxels. Z is 20um voxels. \n",
    "# str_contour_ng_resolution is the previous contour data rescaled to neuroglancer resolution\n",
    "str_contour_ng_resolution = {}\n",
    "\n",
    "for section in str_contour:\n",
    "    # Load (X,Y) coordinates on this contour\n",
    "    section_contours = str_contour[ section ][structure][ threshold ]\n",
    "    # (X,Y) coordinates will be rescaled to the new resolution and placed here\n",
    "    # str_contour_ng_resolution starts at z=0 for simplicity, must provide section offset later on\n",
    "    str_contour_ng_resolution[section-first_sec] = []\n",
    "    # Number of (X,Y) coordinates\n",
    "    num_contours = len( section_contours )\n",
    "    # Cycle through each coordinate pair\n",
    "    for coordinate_pair in range(num_contours):\n",
    "        \n",
    "        curr_coors = section_contours[ coordinate_pair ]\n",
    "        # Rescale coordinate pair and add to new contour dictionary\n",
    "        str_contour_ng_resolution[section-first_sec].append( [scale_xy*curr_coors[0],scale_xy*curr_coors[1]] )\n",
    "        # Replace Min/Max X/Y values with new extremes\n",
    "        min_x = min( scale_xy*curr_coors[0], min_x)\n",
    "        min_y = min( scale_xy*curr_coors[1], min_y)\n",
    "        max_x = max( scale_xy*curr_coors[0], max_x)\n",
    "        max_y = max( scale_xy*curr_coors[1], max_y)\n",
    "\n",
    "        \n",
    "# Cast max and min values to int as they are used to build 3D numpy matrix\n",
    "max_x = int( np.ceil(max_x) ) \n",
    "max_y = int( np.ceil(max_y) )\n",
    "min_x = int( np.floor(min_x) )\n",
    "min_y = int( np.floor(min_y) )\n",
    "# print 'min_x:',min_x\n",
    "# print 'max_x:',max_x\n",
    "# print 'min_y:',min_y\n",
    "# print 'max_y:',max_y\n",
    "\n",
    "# Create empty 'structure_volume' using min and max values found earlier\n",
    "structure_volume = np.zeros( (max_z-min_z, max_y-min_y, max_x-min_x), dtype = np.uint8 )\n",
    "z_voxels,y_voxels,x_voxels =  np.shape(structure_volume)\n",
    "\n",
    "# Go through every slice. For every slice color in the voxels corrosponding to the contour's coordinate pair\n",
    "for slice in range(z_voxels):\n",
    "    slice_contour = np.asarray( str_contour_ng_resolution[slice] )\n",
    "    \n",
    "    for xy_pair in slice_contour:\n",
    "        x_voxel = int(xy_pair[0])-min_x\n",
    "        y_voxel = int(xy_pair[1])-min_y\n",
    "        \n",
    "        # Instead of coloring a single voxel, color all in a specified radius from this voxel!\n",
    "        for x_coor_color_radius in range(1-color_radius,color_radius):\n",
    "            for y_coor_color_radius in range(1-color_radius,color_radius):\n",
    "                \n",
    "                x_displaced_voxel = x_voxel + x_coor_color_radius\n",
    "                y_displaced_voxel = y_voxel + y_coor_color_radius\n",
    "                distance = ( (y_voxel-y_displaced_voxel)**2 + (x_voxel-x_displaced_voxel)**2 )**0.5\n",
    "                # If the temporary coordinate is within the specified radius AND inside the 3D matrix\n",
    "                if distance<color_radius and \\\n",
    "                x_displaced_voxel<x_voxels and \\\n",
    "                y_displaced_voxel<y_voxels and \\\n",
    "                x_displaced_voxel>0 and \\\n",
    "                y_displaced_voxel>0:\n",
    "                    try:\n",
    "                        # Set temporary coordinate to be visible\n",
    "                        structure_volume[slice,y_displaced_voxel,x_displaced_voxel] = 1\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "# structure_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layers['image'] = neuroglancer.ImageLayer(source='precomputed://https://mousebrainatlas-datajoint-jp2k.s3.amazonaws.com/precomputed/MD585_fullres')\n",
    "    s.layers[ structure ] = neuroglancer.SegmentationLayer(\n",
    "        source=neuroglancer.LocalVolume(\n",
    "            data=structure_volume, # Z,Y,X\n",
    "            voxel_size=[10000,10000,20000], # X Y Z\n",
    "            voxel_offset = [min_x-42,min_y+25,min_z] # X Y Z\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroglancer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://127.0.0.1:35679/v/39bde8c0ba73b0bdd2dcfbb2cccda1dc3c8a614b/\" target=\"_blank\">Viewer</a>"
      ],
      "text/plain": [
       "http://127.0.0.1:35679/v/39bde8c0ba73b0bdd2dcfbb2cccda1dc3c8a614b/"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = neuroglancer.Viewer()\n",
    "\n",
    "viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layers['image'] = neuroglancer.ImageLayer(source='precomputed://https://mousebrainatlas-datajoint-jp2k.s3.amazonaws.com/precomputed/MD585_fullres')\n",
    "    #   s.layers['segmentation'] = neuroglancer.SegmentationLayer(source='precomputed://file://./pre_data/12N', selected_alpha=0.3)\n",
    "    s.layers['Structure'] = neuroglancer.SegmentationLayer(\n",
    "        source=neuroglancer.LocalVolume(\n",
    "        data=structure_volume,\n",
    "        voxel_size=[10000,10000,10000],\n",
    "        voxel_offset = [20,20,0]\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neuroglancer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Neuroglancer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wholeslice_to_brainstem = -from_padded_to_wholeslice, from_padded_to_brainstem\n",
    "\n",
    "#from_padded_to_wholeslice\n",
    "rostral_limit = 50\n",
    "caudal_limit = 1188\n",
    "dorsal_limit = 21\n",
    "ventral_limit = 738\n",
    "\n",
    "#from_padded_to_brainstem\n",
    "rostral_limit = 521\n",
    "caudal_limit = 1057\n",
    "dorsal_limit = 128\n",
    "ventral_limit = 465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_structure_contours_from_structure_volumes_v3(volumes, stack, sections, \n",
    "                                                     resolution, level, sample_every=1,\n",
    "                                                    use_unsided_name_as_key=False):\n",
    "    \"\"\"\n",
    "    Re-section atlas volumes and obtain structure contours on each section.\n",
    "    Resolution of output contours are in volume resolution.\n",
    "    v3 supports multiple levels.\n",
    "\n",
    "    Args:\n",
    "        volumes (dict of (3D array, 3-tuple)): {structure: (volume, origin_wrt_wholebrain)}. volume is a 3d array of probability values.\n",
    "        sections (list of int):\n",
    "        resolution (int): resolution of input volumes.\n",
    "        level (float or dict or dict of list): the cut-off probability at which surfaces are generated from probabilistic volumes. Default is 0.5.\n",
    "        sample_every (int): how sparse to sample contour vertices.\n",
    "\n",
    "    Returns:\n",
    "        Dict {section: {name_s: contour vertices}}.\n",
    "    \"\"\"\n",
    "\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    structure_contours_wrt_alignedBrainstemCrop_rawResol = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    converter = CoordinatesConverter(stack=stack, section_list=metadata_cache['sections_to_filenames'][stack].keys())\n",
    "\n",
    "    converter.register_new_resolution('structure_volume', resol_um=convert_resolution_string_to_um(resolution=resolution, stack=stack))\n",
    "    converter.register_new_resolution('image', resol_um=convert_resolution_string_to_um(resolution='raw', stack=stack))\n",
    "    \n",
    "    for name_s, (structure_volume_volResol, origin_wrt_wholebrain_volResol) in volumes.iteritems():\n",
    "\n",
    "        converter.derive_three_view_frames(name_s, \n",
    "        origin_wrt_wholebrain_um=convert_resolution_string_to_um(resolution=resolution, stack=stack) * origin_wrt_wholebrain_volResol,\n",
    "        zdim_um=convert_resolution_string_to_um(resolution=resolution, stack=stack) * structure_volume_volResol.shape[2])\n",
    "\n",
    "        positions_of_all_sections_wrt_structureVolume = converter.convert_frame_and_resolution(\n",
    "        p=np.array(sections)[:,None],\n",
    "        in_wrt=('wholebrain', 'sagittal'), in_resolution='section',\n",
    "        out_wrt=(name_s, 'sagittal'), out_resolution='structure_volume')[..., 2].flatten()\n",
    "            \n",
    "        structure_ddim = structure_volume_volResol.shape[2]\n",
    "        \n",
    "        valid_mask = (positions_of_all_sections_wrt_structureVolume >= 0) & (positions_of_all_sections_wrt_structureVolume < structure_ddim)\n",
    "        if np.count_nonzero(valid_mask) == 0:\n",
    "#             sys.stderr.write(\"%s, valid_mask is empty.\\n\" % name_s)\n",
    "            continue\n",
    "\n",
    "        positions_of_all_sections_wrt_structureVolume = positions_of_all_sections_wrt_structureVolume[valid_mask]\n",
    "        positions_of_all_sections_wrt_structureVolume = np.round(positions_of_all_sections_wrt_structureVolume).astype(np.int)\n",
    "        \n",
    "        if isinstance(level, dict):\n",
    "            level_this_structure = level[name_s]\n",
    "        else:\n",
    "            level_this_structure = level\n",
    "\n",
    "        if isinstance(level_this_structure, float):\n",
    "            level_this_structure = [level_this_structure]\n",
    "                        \n",
    "        for one_level in level_this_structure:\n",
    "\n",
    "            contour_2d_wrt_structureVolume_sectionPositions_volResol = \\\n",
    "            find_contour_points_3d(structure_volume_volResol >= one_level,\n",
    "                                    along_direction='sagittal',\n",
    "                                    sample_every=sample_every,\n",
    "                                    positions=positions_of_all_sections_wrt_structureVolume)\n",
    "\n",
    "            for d_wrt_structureVolume, cnt_uv_wrt_structureVolume in contour_2d_wrt_structureVolume_sectionPositions_volResol.iteritems():\n",
    "\n",
    "                contour_3d_wrt_structureVolume_volResol = np.column_stack([cnt_uv_wrt_structureVolume, np.ones((len(cnt_uv_wrt_structureVolume),)) * d_wrt_structureVolume])\n",
    "\n",
    "    #             contour_3d_wrt_wholebrain_uv_rawResol_section = converter.convert_frame_and_resolution(\n",
    "    #                 p=contour_3d_wrt_structureVolume_volResol,\n",
    "    #                 in_wrt=(name_s, 'sagittal'), in_resolution='structure_volume',\n",
    "    #                 out_wrt=('wholebrain', 'sagittal'), out_resolution='image_image_section')\n",
    "\n",
    "                contour_3d_wrt_alignedBrainstemCrop_uv_rawResol_section = converter.convert_frame_and_resolution(\n",
    "                    p=contour_3d_wrt_structureVolume_volResol,\n",
    "                    in_wrt=(name_s, 'sagittal'), in_resolution='structure_volume',\n",
    "                    out_wrt=('wholebrainXYcropped', 'sagittal'), out_resolution='image_image_section')\n",
    "\n",
    "                assert len(np.unique(contour_3d_wrt_alignedBrainstemCrop_uv_rawResol_section[:,2])) == 1\n",
    "                sec = int(contour_3d_wrt_alignedBrainstemCrop_uv_rawResol_section[0,2])\n",
    "\n",
    "                if use_unsided_name_as_key:\n",
    "                    name = convert_to_unsided_label(name_s)\n",
    "                else:\n",
    "                    name = name_s\n",
    "\n",
    "                structure_contours_wrt_alignedBrainstemCrop_rawResol[sec][name][one_level] = contour_3d_wrt_alignedBrainstemCrop_uv_rawResol_section[..., :2]\n",
    "        \n",
    "    return structure_contours_wrt_alignedBrainstemCrop_rawResol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
