{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Precision WorkStation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename \"lossless\" to \"raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for stack in all_nissl_stacks:\n",
    "\n",
    "    for section in metadata_cache['valid_sections'][stack]:\n",
    "\n",
    "        in_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=2, section=section, version='jpeg', resol='lossless')\n",
    "\n",
    "        out_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=2, section=section, version='jpeg', resol='raw')\n",
    "\n",
    "        create_parent_dir_if_not_exists(out_fp)\n",
    "        \n",
    "        execute_command('ln -s %s %s' % (in_fp, out_fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for stack in all_nissl_stacks:\n",
    "\n",
    "    for section in metadata_cache['valid_sections'][stack]:\n",
    "\n",
    "        in_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=2, section=section, version=None, resol='lossless')\n",
    "\n",
    "        out_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=2, section=section, version=None, resol='raw')\n",
    "\n",
    "        create_parent_dir_if_not_exists(out_fp)\n",
    "        \n",
    "        execute_command('ln -s %s %s' % (in_fp, out_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for stack in all_nissl_stacks:\n",
    "\n",
    "    for section in metadata_cache['valid_sections'][stack]:\n",
    "\n",
    "        in_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=2, section=section, version='gray', resol='lossless')\n",
    "\n",
    "        out_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=2, section=section, version='gray', resol='raw')\n",
    "\n",
    "        create_parent_dir_if_not_exists(out_fp)\n",
    "        \n",
    "        execute_command('ln -s %s %s' % (in_fp, out_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD585'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.transform import warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack, redownload=True) \n",
    "valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "print len(valid_filenames), 'valid filenames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_image_types(from_type, to_type):\n",
    "    \n",
    "    from_prep_id = from_type['prep_id']\n",
    "    to_prep_id = to_type['prep_id']\n",
    "    \n",
    "    if from_prep_id is None and to_prep_id == 1: # in-plane alignment\n",
    "        pass\n",
    "    \n",
    "    elif (from_prep_id == 1 or from_prep_id == 'alignedPadded') and (to_prep_id == 5 or to_prep_id == 'alignedWithMargin'): # alignedPadded to alignedWithMargin\n",
    "    \n",
    "        alignedWithMargin_xmin, alignedWithMargin_xmax,\\\n",
    "        alignedWithMargin_ymin, alignedWithMargin_ymax = DataManager.load_cropbox_v2(stack=stack, anchor_fn=None, \n",
    "                                                            prep_id='alignedWithMargin',\n",
    "                                                           return_dict=False, only_2d=True)\n",
    "        \n",
    "        in_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=1, section=section, version=version, resol='thumbnail')\n",
    "\n",
    "        out_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=5, section=section, version=version, resol='thumbnail')\n",
    "\n",
    "        create_parent_dir_if_not_exists(out_fp)\n",
    "\n",
    "        t = time.time()\n",
    "        im_prep1 = imread(in_fp)\n",
    "        im_prep5 = im_prep1[alignedWithMargin_ymin:alignedWithMargin_ymax+1, \n",
    "                            alignedWithMargin_xmin:alignedWithMargin_xmax+1]        \n",
    "        save_data(im_prep5, out_fp)            \n",
    "        sys.stderr.write('Crop alignedPadded to generate alignedWithMargin: %.2f seconds.\\n' % (time.time() - t))\n",
    "        \n",
    "    elif from_prep_id == 1 and to_prep_id == 2: # alignedWithMargin to alignedBrainstemCrop\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_tif_to_jpeg(in_fp, out_fp):\n",
    "    t = time.time()\n",
    "    execute_command(\"convert %(in_fp)s %(out_fp)s\" % {'in_fp': in_fp, 'out_fp': out_fp})\n",
    "    sys.stderr.write('Convert to JPEG: %.2f seconds.\\n' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to gray\n",
    "\n",
    "for stack in ['MD585']:\n",
    "\n",
    "    for section in metadata_cache['valid_sections'][stack]:\n",
    "\n",
    "        in_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=2, section=section, version=None, resol='raw')\n",
    "\n",
    "        out_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=2, section=section, version='gray', resol='raw')\n",
    "\n",
    "        create_parent_dir_if_not_exists(out_fp)\n",
    "\n",
    "#         t = time.time()\n",
    "#         im_rgb = imread(in_fp)\n",
    "#         sys.stderr.write('Load: %.2f seconds.\\n' % (time.time() - t))\n",
    "        \n",
    "#         t = time.time()\n",
    "#         im_gray = img_as_ubyte(rgb2gray(im_rgb))\n",
    "# #         im_gray = im_rgb[..., 2]\n",
    "#         sys.stderr.write('Convert RGB to gray: %.2f seconds.\\n' % (time.time() - t))\n",
    "        \n",
    "#         t = time.time()\n",
    "#         save_data(im_gray, out_fp)\n",
    "#         sys.stderr.write('Save: %.2f seconds.\\n' % (time.time() - t))\n",
    "\n",
    "        t = time.time()\n",
    "        im_rgb = imread(in_fp)\n",
    "        sys.stderr.write('Load: %.2f seconds.\\n' % (time.time() - t))\n",
    "        \n",
    "        t = time.time()\n",
    "        im_gray = img_as_ubyte(rgb2gray(im_rgb))\n",
    "#         im_gray = im_rgb[..., 2]\n",
    "        sys.stderr.write('Convert RGB to gray: %.2f seconds.\\n' % (time.time() - t))\n",
    "        \n",
    "        t = time.time()\n",
    "        save_data(im_gray, out_fp, upload_s3=False)\n",
    "        sys.stderr.write('Save: %.2f seconds.\\n' % (time.time() - t))\n",
    "        \n",
    "#         upload_to_s3(out_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to JPEG\n",
    "\n",
    "for stack in ['MD595']:\n",
    "# for stack in all_nissl_stacks:\n",
    "\n",
    "    for section in metadata_cache['valid_sections'][stack]:\n",
    "\n",
    "        in_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=2, section=section, version='gray', resol='raw')\n",
    "\n",
    "        out_fp = \\\n",
    "        DataManager.get_image_filepath_v2(stack=stack, prep_id=2, section=section, version='grayJpeg', resol='raw')\n",
    "\n",
    "        create_parent_dir_if_not_exists(out_fp)\n",
    "\n",
    "        convert_tif_to_jpeg(in_fp, out_fp)\n",
    "        \n",
    "#         upload_to_s3(out_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert original alignedBrainstemCrop cropbox file to section limit json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for stack in ['MD658', 'MD661', 'MD662']:\n",
    "for stack in ['MD635', 'MD653', 'MD652', 'MD642']:\n",
    "\n",
    "    alignedBrainstemCrop_secmin, alignedBrainstemCrop_secmax = DataManager.load_cropbox(stack=stack)[4:]\n",
    "\n",
    "    alignedBrainstemCrop_seclims = {'left_section_limit': alignedBrainstemCrop_secmin, \n",
    "                                    'right_section_limit': alignedBrainstemCrop_secmax}\n",
    "    \n",
    "    save_data(alignedBrainstemCrop_seclims, \n",
    "          DataManager.get_section_limits_filename_v2(stack=stack, anchor_fn=None, prep_id='alignedBrainstemCrop'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert original alignedBrainstemCrop cropbox file to bbox json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp \"/data/CSHL_data_processed/MD657/MD657_alignedTo_MD657-F44-2017.02.18-06.06.27_MD657_1_0130_prep2_cropbox.json\" \"s3://mousebrainatlas-data/CSHL_data_processed/MD657/MD657_alignedTo_MD657-F44-2017.02.18-06.06.27_MD657_1_0130_prep2_cropbox.json\"\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_nissl_stacks:\n",
    "# for stack in ['MD658', 'MD661', 'MD662']:\n",
    "# for stack in ['MD635', 'MD653', 'MD652', 'MD642']:\n",
    "for stack in ['MD657']:\n",
    "    \n",
    "    alignedBrainstemCrop_xmin, alignedBrainstemCrop_xmax, \\\n",
    "    alignedBrainstemCrop_ymin, alignedBrainstemCrop_ymax = DataManager.load_cropbox(stack=stack)[:4]\n",
    "\n",
    "    alignedBrainstemCrop_cropbox = {'rostral_limit': alignedBrainstemCrop_xmin, 'caudal_limit': alignedBrainstemCrop_xmax, \n",
    "     'dorsal_limit': alignedBrainstemCrop_ymin, 'ventral_limit': alignedBrainstemCrop_ymax}\n",
    "    \n",
    "    save_data(alignedBrainstemCrop_cropbox, \n",
    "          DataManager.get_cropbox_filename_v2(stack=stack, anchor_fn=None, prep_id='alignedBrainstemCrop'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify bounding box for \"wholebrainWithMargin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_resol = 'down32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for stack in ['MD589']:\n",
    "# for stack in all_nissl_stacks:\n",
    "    \n",
    "    bbox_all_images = []\n",
    "    for fn in metadata_cache['valid_filenames'][stack]:\n",
    "        mask_tb_alignedPadded = DataManager.load_thumbnail_mask_v3(stack=stack, prep_id=1, fn=fn)\n",
    "        bbox = bbox_2d(mask_tb_alignedPadded)\n",
    "        bbox_all_images.append(bbox)\n",
    "    bbox_all_images = np.array(bbox_all_images)\n",
    "\n",
    "#     bbox_all_images = np.array([\n",
    "#         bbox_2d(DataManager.load_thumbnail_mask_v3(stack=stack, prep_id=1, fn=fn))\n",
    "#         for fn in metadata_cache['valid_filenames'][stack]\n",
    "#     ])\n",
    "    \n",
    "    # Are the bounding boxes reasonable? If some numbers stand out, go back to check the mask.\n",
    "    plt.figure(figsize=(10,5));\n",
    "    plt.plot(bbox_all_images[:,0], label='xmin')\n",
    "    plt.plot(bbox_all_images[:,1], label='xmax')\n",
    "    plt.plot(bbox_all_images[:,2], label='ymin')\n",
    "    plt.plot(bbox_all_images[:,3], label='ymax')\n",
    "    plt.legend();\n",
    "    plt.show();\n",
    "    \n",
    "    margin_um = 736.\n",
    "    margin = int(np.round(margin_um / convert_resolution_string_to_um(resolution=tb_resol, stack=stack)))\n",
    "    alignedWithMargin_xmin, alignedWithMargin_ymin = np.maximum(bbox_all_images[:, [0,2]].min(axis=0) - margin, 0)\n",
    "    alignedWithMargin_xmax, alignedWithMargin_ymax = np.minimum(bbox_all_images[:, [1,3]].max(axis=0) + margin, \n",
    "                                                                [mask_tb_alignedPadded.shape[1]-1, mask_tb_alignedPadded.shape[0]-1])\n",
    "    \n",
    "    print alignedWithMargin_xmin, alignedWithMargin_xmax, alignedWithMargin_ymin, alignedWithMargin_ymax \n",
    "    \n",
    "    alignedWithMargin_cropbox = {'rostral_limit': alignedWithMargin_xmin, 'caudal_limit': alignedWithMargin_xmax, \n",
    " 'dorsal_limit': alignedWithMargin_ymin, 'ventral_limit': alignedWithMargin_ymax}\n",
    "    \n",
    "    save_data(alignedWithMargin_cropbox, \n",
    "              DataManager.get_cropbox_filename_v2(stack=stack, anchor_fn=None, prep_id='alignedWithMargin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE*: If any of the four sides looks out of place, identify the section and double-check its mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_outlier(a, t, mode='max'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        t(float): The peak must be different from neighbor by this much.\n",
    "    \"\"\"\n",
    "    if mode == 'max':\n",
    "        return np.r_[True, a[1:] - a[:-1] > t] & np.r_[a[:-1] - a[1:] > t, True]\n",
    "    elif mode == 'min':\n",
    "        return np.r_[True, a[1:] - a[:-1] < -t] & np.r_[a[:-1] - a[1:] < -t, True]\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identify sections whose bboxes are outliers.\n",
    "\n",
    "print 'xmin outlier', [metadata_cache['valid_filenames'][stack][s] for s in np.where(find_outlier(bbox_all_images[:,0], 40, 'min'))[0]]\n",
    "print 'xmax outlier', [metadata_cache['valid_filenames'][stack][s] for s in np.where(find_outlier(bbox_all_images[:,1], 40, 'max'))[0]]\n",
    "print 'ymin outlier', [metadata_cache['valid_filenames'][stack][s] for s in np.where(find_outlier(bbox_all_images[:,2], 40, 'min'))[0]]\n",
    "print 'ymax outlier', [metadata_cache['valid_filenames'][stack][s] for s in np.where(find_outlier(bbox_all_images[:,3], 40, 'max'))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for fn in metadata_cache['valid_filenames'][stack]:\n",
    "#     mask_tb_alignedPadded = DataManager.load_thumbnail_mask_v3(stack=stack, prep_id=1, fn=fn)\n",
    "#     plt.figure();\n",
    "#     plt.imshow(mask_tb_alignedPadded[alignedWithMargin_ymin:alignedWithMargin_ymax+1, \n",
    "#                                      alignedWithMargin_xmin:alignedWithMargin_xmax+1], cmap=plt.cm.gray)\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate prep5 thumbnails from prep1 thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for stack in all_nissl_stacks:\n",
    "\n",
    "    alignedWithMargin_xmin, alignedWithMargin_xmax,\\\n",
    "    alignedWithMargin_ymin, alignedWithMargin_ymax = DataManager.load_cropbox_v2(stack=stack, anchor_fn=None, \n",
    "                                                            prep_id='alignedWithMargin',\n",
    "                                                           return_dict=False, only_2d=True)\n",
    "            \n",
    "#     for section in metadata_cache['valid_sections_all'][stack]: # for CHATM2 and CHATM3\n",
    "    for section in metadata_cache['valid_sections'][stack]: # for MD589 etc.\n",
    "        \n",
    "#         for version in ['NtbNormalized', 'mask']:\n",
    "        for version in [None, 'mask']:\n",
    "\n",
    "            in_fp = \\\n",
    "            DataManager.get_image_filepath_v2(stack=stack, prep_id=1, section=section, version=version, resol='thumbnail')\n",
    "\n",
    "            out_fp = \\\n",
    "            DataManager.get_image_filepath_v2(stack=stack, prep_id=5, section=section, version=version, resol='thumbnail')\n",
    "\n",
    "            create_parent_dir_if_not_exists(out_fp)\n",
    "\n",
    "            t = time.time()\n",
    "\n",
    "            im_prep1 = imread(in_fp)\n",
    "            im_prep5 = im_prep1[alignedWithMargin_ymin:alignedWithMargin_ymax+1, \n",
    "                                alignedWithMargin_xmin:alignedWithMargin_xmax+1]        \n",
    "            save_data(im_prep5, out_fp)\n",
    "            \n",
    "            sys.stderr.write('Generate prep5: %.2f seconds.\\n' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct intensity volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Refer to `reconstruct/construct_intensity_volume_v3.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output_resolution = 'down32'\n",
    "output_resolution = '10.0um'\n",
    "\n",
    "# tb_version = 'NtbNormalized'\n",
    "tb_version = None\n",
    "tb_resol = 'thumbnail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for stack in all_nissl_stacks:\n",
    "# for stack in ['MD590']:\n",
    "\n",
    "    images = {}\n",
    "\n",
    "#     for sec in metadata_cache['valid_sections_all'][stack]:\n",
    "    for sec in metadata_cache['valid_sections'][stack]:\n",
    "\n",
    "        img_rgb = DataManager.load_image_v2(stack, section=sec, \n",
    "                                            resol=tb_resol, \n",
    "                                            prep_id='alignedWithMargin', \n",
    "                                            version=tb_version)\n",
    "        img = img_as_ubyte(rgb2gray(img_rgb)) # Use greylevel\n",
    "\n",
    "        mask = DataManager.load_image_v2(stack=stack, section=sec, \n",
    "                                         prep_id='alignedWithMargin', \n",
    "                                         resol=tb_resol, \n",
    "                                         version='mask')\n",
    "        img[~mask] = 0\n",
    "\n",
    "        images[sec] = img\n",
    "\n",
    "    # Specify isotropic resolution of the output volume.\n",
    "    voxel_size_um = convert_resolution_string_to_um(resolution=output_resolution, stack=stack)\n",
    "\n",
    "    input_image_resolution_um = convert_resolution_string_to_um(resolution=tb_resol, stack=stack)\n",
    "\n",
    "    volume_outVolResol, volume_origin_wrt_wholebrainWithMargin_outVolResol = images_to_volume_v2(images=images, \n",
    "                                                spacing_um=20.,\n",
    "                                                in_resol_um=input_image_resolution_um,\n",
    "                                                out_resol_um=voxel_size_um)\n",
    "    print volume_outVolResol.shape\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    prep5_origin_wrt_prep1_tbResol = DataManager.load_cropbox_v2(stack=stack, only_2d=True, prep_id='alignedWithMargin')\n",
    "\n",
    "    loaded_cropbox_resol = 'thumbnail'\n",
    "\n",
    "    prep5_origin_wrt_prep1_outVolResol = prep5_origin_wrt_prep1_tbResol * \\\n",
    "    convert_resolution_string_to_um(resolution=loaded_cropbox_resol, stack=stack) / voxel_size_um\n",
    "\n",
    "    wholebrainWithMargin_origin_wrt_wholebrain_outVolResol = np.r_[np.round(prep5_origin_wrt_prep1_outVolResol).astype(np.int)[[0,2]], 0]\n",
    "    # wholebrainWithMargin_origin_wrt_wholebrain = np.array([0,0,0])\n",
    "\n",
    "    volume_origin_wrt_wholebrain_outVolResol = volume_origin_wrt_wholebrainWithMargin_outVolResol + wholebrainWithMargin_origin_wrt_wholebrain_outVolResol\n",
    "\n",
    "    ########################################\n",
    "\n",
    "    stack_spec = dict(name=stack,\n",
    "                      resolution=output_resolution,\n",
    "                      prep_id='wholebrainWithMargin',\n",
    "                      vol_type='intensity')\n",
    "    \n",
    "    save_data(volume_outVolResol, \n",
    "              fp=DataManager.get_original_volume_filepath_v2(stack_spec=stack_spec, structure=None))\n",
    "\n",
    "    save_data(volume_origin_wrt_wholebrain_outVolResol, \n",
    "              fp=DataManager.get_original_volume_origin_filepath_v3(stack_spec=stack_spec, structure=None))\n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    display_volume_sections(volume_outVolResol, cmap=plt.cm.gray, every=20, title_fontsize=20)\n",
    "    \n",
    "    ###########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop, generate prep2 raw from prep5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocess import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(stack, img_name, version, resol, x,y,w,h):\n",
    "\n",
    "    input_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=5, resol=resol, version=version, fn=img_name)\n",
    "    output_fp = DataManager.get_image_filepath_v2(stack=stack, fn=img_name, prep_id=2, version=version, resol=resol)\n",
    "\n",
    "    img = imread(input_fp)\n",
    "    save_data(img[y:y+h, x:x+w], output_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for stack in ['CHATM2', 'CHATM3']:\n",
    "for stack in ['MD589']:\n",
    "\n",
    "    alignedBrainstemCrop_xmin, alignedBrainstemCrop_xmax, \\\n",
    "    alignedBrainstemCrop_ymin, alignedBrainstemCrop_ymax = \\\n",
    "    DataManager.load_cropbox_v2(stack=stack, prep_id='alignedBrainstemCrop', only_2d=True)\n",
    "\n",
    "    alignedWithMargin_xmin, alignedWithMargin_xmax,\\\n",
    "    alignedWithMargin_ymin, alignedWithMargin_ymax = DataManager.load_cropbox_v2(stack=stack, anchor_fn=None, \n",
    "                                                            prep_id='alignedWithMargin',\n",
    "                                                           return_dict=False, only_2d=True)\n",
    "\n",
    "    alignedBrainstemCrop_xmin_wrt_alignedWithMargin = alignedBrainstemCrop_xmin - alignedWithMargin_xmin\n",
    "    alignedBrainstemCrop_xmax_wrt_alignedWithMargin = alignedBrainstemCrop_xmax - alignedWithMargin_xmin\n",
    "    alignedBrainstemCrop_ymin_wrt_alignedWithMargin = alignedBrainstemCrop_ymin - alignedWithMargin_ymin\n",
    "    alignedBrainstemCrop_ymax_wrt_alignedWithMargin = alignedBrainstemCrop_ymax - alignedWithMargin_ymin\n",
    "\n",
    "    print alignedBrainstemCrop_xmin_wrt_alignedWithMargin,\\\n",
    "    alignedBrainstemCrop_xmax_wrt_alignedWithMargin,\\\n",
    "    alignedBrainstemCrop_ymin_wrt_alignedWithMargin,\\\n",
    "    alignedBrainstemCrop_ymax_wrt_alignedWithMargin\n",
    "\n",
    "    x_tb = alignedBrainstemCrop_xmin_wrt_alignedWithMargin\n",
    "    y_tb = alignedBrainstemCrop_ymin_wrt_alignedWithMargin\n",
    "    w_tb = alignedBrainstemCrop_xmax_wrt_alignedWithMargin - alignedBrainstemCrop_xmin_wrt_alignedWithMargin + 1\n",
    "    h_tb = alignedBrainstemCrop_ymax_wrt_alignedWithMargin - alignedBrainstemCrop_ymin_wrt_alignedWithMargin + 1\n",
    "\n",
    "#     for version in ['NtbNormalizedAdaptiveInvertedGamma', 'CHAT']:\n",
    "#     for version in ['CHAT']:\n",
    "    for version in ['NtbNormalizedAdaptiveInvertedGamma']:\n",
    "#     for version in ['mask']:\n",
    "#         for resol in ['thumbnail']:\n",
    "        for resol in ['raw']:\n",
    "            \n",
    "            if resol == 'raw':\n",
    "                x = x_tb * 32\n",
    "                y = y_tb * 32\n",
    "                w = w_tb * 32\n",
    "                h = h_tb * 32\n",
    "            elif resol == 'thumbnail':\n",
    "                x = x_tb\n",
    "                y = y_tb\n",
    "                w = w_tb\n",
    "                h = h_tb\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "#             input_dir = DataManager.get_image_dir_v2(stack=stack, prep_id=5, version=version, resol='raw')\n",
    "            out_dir = DataManager.get_image_dir_v2(stack=stack, prep_id=2, resol=resol, version=version)\n",
    "            print 'out_dir:', out_dir\n",
    "#             script = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v3.py')\n",
    "\n",
    "    #         ! rm -rf {out_dir}\n",
    "            create_if_not_exists(out_dir)\n",
    "\n",
    "            t = time.time()\n",
    "\n",
    "            pool = Pool(8)\n",
    "            _ = pool.map(lambda img_name: f(stack=stack, img_name=img_name, version=version, resol=resol, \n",
    "                                            x=x, y=y, w=w, h=h), \n",
    "                         metadata_cache['valid_filenames'][stack])\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "\n",
    "#             for img_name in metadata_cache['valid_filenames'][stack]:\n",
    "#                 f(stack=stack, img_name=img_name, version=version, resol=resol, \n",
    "#                                             x=x, y=y, w=w, h=h)\n",
    "\n",
    "        #     run_distributed('convert \\\"%%(input_fp)s\\\" -crop %(w)dx%(h)d+%(x)d+%(y)d  \\\"%%(output_fp)s\\\"' % \\\n",
    "        #                     {'w':w_raw, 'h':h_raw, 'x':x_raw, 'y':y_raw},\n",
    "        #                     kwargs_list=[{'input_fp': DataManager.get_image_filepath_v2(stack=stack, prep_id=5, resol='raw', version=version, fn=img_name),\n",
    "        #                                   'output_fp': DataManager.get_image_filepath_v2(stack=stack, fn=img_name, prep_id=2, version=version, resol='raw')}\n",
    "        #                                  for img_name in metadata_cache['valid_filenames'][stack]],\n",
    "        # #                                  for img_name in ['CHATM3_slide35_2018_02_17-S1']],\n",
    "        #                     argument_type='single',\n",
    "        #                    jobs_per_node=1,\n",
    "        #                    local_only=True)\n",
    "\n",
    "            # wait_qsub_complete()\n",
    "\n",
    "            print 'done in', time.time() - t, 'seconds' # 1500s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
