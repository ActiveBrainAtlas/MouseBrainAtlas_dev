{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patches Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named utilities2015",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f9e3052e4a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'REPO_DIR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/utilities'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutilities2015\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named utilities2015"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities_NOMXNET import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_id = 1\n",
    "stack = 'MD589'\n",
    "\n",
    "paired_structures = ['5N', '6N', '7N', '7n', 'Amb', 'LC', 'LRt', 'Pn', 'Tz', 'VLL', 'RMC', \\\n",
    "                     'SNC', 'SNR', '3N', '4N', 'Sp5I', 'Sp5O', 'Sp5C', 'PBG', '10N', 'VCA', 'VCP', 'DC']\n",
    "singular_structures = ['AP', '12N', 'RtTg', 'SC', 'IC']\n",
    "\n",
    "all_structures = paired_structures + singular_structures\n",
    "\n",
    "# 1: {'patch_size': 224, 'spacing': 56}\n",
    "patch_loc_root = ROOT_DIR+'/CSHL_patch_locations/'+stack+'/'+stack+'_prep2_gray_win1/'\n",
    "images_root = ROOT_DIR+'/CSHL_data_processed/'+stack+'/'+stack+'_prep2_thumbnail/'\n",
    "raw_images_root = ROOT_DIR+'/CSHL_data_processed/'+stack+'/'+stack+'_prep2_lossless_gray/'\n",
    "\n",
    "patch_fn_list = ! ls $patch_loc_root\n",
    "image_fn_list = ! ls $images_root\n",
    "raw_image_fn_list = ! ls $raw_images_root\n",
    "\n",
    "filename_to_section, section_to_filename = DataManager.load_sorted_filenames( stack )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowing_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download essential files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_download_from_s3( rel_fp, recursive=True ):\n",
    "    s3_fp = 's3://mousebrainatlas-data/'+rel_fp\n",
    "    local_fp = os.environ['ROOT_DIR']+rel_fp\n",
    "\n",
    "    if os.path.exists(local_fp):\n",
    "        print('ALREADY DOWNLOADED FILE')\n",
    "        return \n",
    "    \n",
    "    if recursive:\n",
    "        ! aws s3 cp --recursive $s3_fp $local_fp\n",
    "    else:\n",
    "        ! aws s3 cp $s3_fp $local_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_download_from_s3('CSHL_data_processed/'+stack+'/'+stack+'_metadata_cache.json', recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_download_from_s3('CSHL_patch_locations/'+stack+'/'+stack+'_prep2_gray_win1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "setup_download_from_s3('CSHL_data_processed/'+stack+'/'+stack+'_prep2_thumbnail/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup_download_from_s3('CSHL_data_processed/'+stack+'/'+stack+'_prep2_lossless/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify patches based on human annotation\n",
    "--script identify_patch_class_based_on_labeling_v3_human_annotations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp, latest_timestamp = DataManager.get_annotation_filepath(stack, by_human=True, suffix='contours', \\\n",
    "            timestamp='latest', return_timestamp=True, annotation_rootdir=ANNOTATION_ROOTDIR, download_s3=False)\n",
    "grid_index_class_lookup_fp = \\\n",
    "    DataManager.get_annotation_to_grid_indices_lookup_filepath(stack=stack, win_id=win_id, \n",
    "                                                               by_human=True, timestamp=latest_timestamp)\n",
    "if not os.path.exists(grid_index_class_lookup_fp):\n",
    "    ! python identify_patch_class_based_on_labeling_v3_human_annotations.py MD589 1\n",
    "else:\n",
    "    print('ALREADY IDENTIFY PATCHES')\n",
    "\n",
    "grid_index_class_lookup = load_hdf_v2(grid_index_class_lookup_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to x, y locations using 'all_locs'\n",
    "all_locs = grid_parameters_to_sample_locations(win_id=win_id, stack=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List valid patches according to structures and sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patch_locations = {}\n",
    "\n",
    "for structure in all_structures:    \n",
    "    valid_sections = []\n",
    "    try:\n",
    "        possibly_valid_sections = grid_index_class_lookup[structure].keys()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('SKIPPING: '+structure)\n",
    "        continue\n",
    "        \n",
    "    all_patch_locations[structure] = {}\n",
    "\n",
    "    # Make a list of all sections where patches actually exist\n",
    "    for section in possibly_valid_sections:\n",
    "        # If this table entry is a numpy array, then it is filled with data. Otherwise (float) it is 'nan'\n",
    "        if isinstance(grid_index_class_lookup[structure][section], np.ndarray):\n",
    "            valid_sections.append( section )\n",
    "            \n",
    "    for section in valid_sections:\n",
    "        valid_patch_indices = grid_index_class_lookup[structure][ section ]\n",
    "        patch_coors =  all_locs[ valid_patch_indices ].tolist()\n",
    "        all_patch_locations[structure][int(section)] = patch_coors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch examples display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pts_str = []\n",
    "y_pts_str = []\n",
    "x_raw = []\n",
    "y_raw = []\n",
    "x_offset = -50\n",
    "y_offset = -11\n",
    "structure = 'DC'\n",
    "section = all_patch_locations[structure].keys()[20]\n",
    "valid_patch_indices = grid_index_class_lookup[structure][ section ]\n",
    "print 'Number of Positive Patches:',len(valid_patch_indices)\n",
    "\n",
    "for x, y in all_locs[valid_patch_indices]:\n",
    "    x_raw.append( (float(x)) )\n",
    "    y_raw.append( (float(y)) )\n",
    "    x_pts_str.append( (float(x)/32)+x_offset )\n",
    "    y_pts_str.append( (float(y)/32)+y_offset )\n",
    "    \n",
    "img = cv2.imread( images_root+section_to_filename[section]+'_prep2_thumbnail.tif' , 2)\n",
    "#plt.figure( figsize=(50,50) )\n",
    "plt.imshow( img, cmap='gray')\n",
    "\n",
    "plt.scatter(x_pts_str, y_pts_str, s=1, c='blue', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = cv2.imread( raw_images_root+section_to_filename[section]+'_prep2_lossless_gray.tif', 2)\n",
    "index = 50\n",
    "x = int( float( all_patch_locations[structure][section][index][0] ) ) + x_offset*32\n",
    "y = int( float( all_patch_locations[structure][section][index][1] ) ) + y_offset*32\n",
    "\n",
    "patch = img[y:y+224,x:x+224]\n",
    "\n",
    "\n",
    "plt.imshow( patch, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save patches to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset = -1600\n",
    "y_offset = -352\n",
    "! mkdir $ROOT_DIR/CSHL_patches\n",
    "! mkdir $ROOT_DIR/CSHL_patches/$stack\n",
    "for structure in all_patch_locations.keys():\n",
    "    savepath=ROOT_DIR+'/CSHL_patches/'+stack+'/'+structure\n",
    "    if os.path.exists(savepath):\n",
    "        print(structure+' ALREADY EXIST')\n",
    "        continue\n",
    "    else:\n",
    "        ! mkdir $savepath\n",
    "    for section in all_patch_locations[structure].keys():\n",
    "        img = cv2.imread( raw_images_root+section_to_filename[section]+'_prep2_lossless_gray.tif', 2)\n",
    "        for index in range(len(all_patch_locations[structure][section])):\n",
    "            x = int( float( all_patch_locations[structure][section][index][0] ) ) + x_offset\n",
    "            y = int( float( all_patch_locations[structure][section][index][1] ) ) + y_offset\n",
    "            patch = img[y:y+224,x:x+224]\n",
    "            filename=savepath+'/'+str(section)+'_'+str(index)+'.tif'\n",
    "            cv2.imwrite(filename, patch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patch_locations = {}\n",
    "\n",
    "for structure in all_structures: \n",
    "    structure=structure+'_surround_200um_noclass'\n",
    "    valid_sections = []\n",
    "    try:\n",
    "        possibly_valid_sections = grid_index_class_lookup[structure].keys()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('SKIPPING: '+structure)\n",
    "        continue\n",
    "        \n",
    "    all_patch_locations[structure] = {}\n",
    "\n",
    "    # Make a list of all sections where patches actually exist\n",
    "    for section in possibly_valid_sections:\n",
    "        # If this table entry is a numpy array, then it is filled with data. Otherwise (float) it is 'nan'\n",
    "        if isinstance(grid_index_class_lookup[structure][section], np.ndarray):\n",
    "            valid_sections.append( section )\n",
    "            \n",
    "    for section in valid_sections:\n",
    "        valid_patch_indices = grid_index_class_lookup[structure][ section ]\n",
    "        patch_coors =  all_locs[ valid_patch_indices ].tolist()\n",
    "        all_patch_locations[structure][int(section)] = patch_coors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pts_str = []\n",
    "y_pts_str = []\n",
    "x_raw = []\n",
    "y_raw = []\n",
    "x_offset = -50\n",
    "y_offset = -11\n",
    "structure = 'DC'+'_surround_200um_noclass'\n",
    "section = all_patch_locations[structure].keys()[20]\n",
    "valid_patch_indices = grid_index_class_lookup[structure][ section ]\n",
    "print 'Number of Negative Patches:',len(valid_patch_indices)\n",
    "\n",
    "for x, y in all_locs[valid_patch_indices]:\n",
    "    x_raw.append( (float(x)) )\n",
    "    y_raw.append( (float(y)) )\n",
    "    x_pts_str.append( (float(x)/32)+x_offset )\n",
    "    y_pts_str.append( (float(y)/32)+y_offset )\n",
    "    \n",
    "img = cv2.imread( images_root+section_to_filename[section]+'_prep2_thumbnail.tif' , 2)\n",
    "#plt.figure( figsize=(50,50) )\n",
    "plt.imshow( img, cmap='gray')\n",
    "\n",
    "plt.scatter(x_pts_str, y_pts_str, s=1, c='blue', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread( raw_images_root+section_to_filename[section]+'_prep2_lossless_gray.tif', 2)\n",
    "index = 20\n",
    "x = int( float( all_patch_locations[structure][section][index][0] ) ) + x_offset*32\n",
    "y = int( float( all_patch_locations[structure][section][index][1] ) ) + y_offset*32\n",
    "\n",
    "patch = img[y:y+224,x:x+224]\n",
    "\n",
    "\n",
    "plt.imshow( patch, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset = -1600\n",
    "y_offset = -352\n",
    "! mkdir $ROOT_DIR/CSHL_patches\n",
    "! mkdir $ROOT_DIR/CSHL_patches/$stack\n",
    "for structure in all_patch_locations.keys():\n",
    "    savepath=ROOT_DIR+'/CSHL_patches/'+stack+'/'+structure\n",
    "    if os.path.exists(savepath):\n",
    "        print(structure+' ALREADY EXIST')\n",
    "        continue\n",
    "    else:\n",
    "        ! mkdir $savepath\n",
    "    for section in all_patch_locations[structure].keys():\n",
    "        img = cv2.imread( raw_images_root+section_to_filename[section]+'_prep2_lossless_gray.tif', 2)\n",
    "        for index in range(len(all_patch_locations[structure][section])):\n",
    "            x = int( float( all_patch_locations[structure][section][index][0] ) ) + x_offset\n",
    "            y = int( float( all_patch_locations[structure][section][index][1] ) ) + y_offset\n",
    "            patch = img[y:y+224,x:x+224]\n",
    "            filename=savepath+'/'+str(section)+'_'+str(index)+'.tif'\n",
    "            cv2.imwrite(filename, patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $ROOT_DIR/CSHL_patches/$stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "for dir in glob('*'):\n",
    "    print dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mouserbrainatlas",
   "language": "python",
   "name": "mouserbrainatlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
