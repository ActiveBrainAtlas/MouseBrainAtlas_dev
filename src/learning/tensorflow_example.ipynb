{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *\n",
    "from distributed_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD585'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotation_grid_indices_fp = os.path.join(ANNOTATION_ROOTDIR, stack, stack + '_annotation_grid_indices.h5')\n",
    "download_from_s3(annotation_grid_indices_fp)\n",
    "grid_indices_per_label = read_hdf(annotation_grid_indices_fp, 'grid_indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_id = 30\n",
    "classifier_properties = classifier_settings.loc[classifier_id]\n",
    "\n",
    "margin = classifier_properties['margin']\n",
    "model = classifier_properties['model']\n",
    "sample_weighting = classifier_properties['sample_weighting']\n",
    "neg_composition = classifier_properties['neg_composition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine which labels to load.\n",
    "\n",
    "structures_to_sample = all_known_structures\n",
    "negative_labels_to_sample = [s + '_negative' for s in structures_to_sample]\n",
    "\n",
    "margins_to_sample = [margin] # (200: 100 um, 500: 250 um)\n",
    "surround_positive_labels_to_sample = [convert_to_surround_name(s, margin=m, suffix=surr_l) \n",
    "                             for m in margins_to_sample\n",
    "                             for s in structures_to_sample \n",
    "                             for surr_l in structures_to_sample\n",
    "                             if surr_l != s]\n",
    "surround_noclass_labels_to_sample = [convert_to_surround_name(s, margin=m, suffix='noclass') \n",
    "                             for m in margins_to_sample\n",
    "                             for s in structures_to_sample]\n",
    "\n",
    "if neg_composition == 'neg_has_everything_else':\n",
    "    labels_to_sample = structures_to_sample + negative_labels_to_sample\n",
    "elif neg_composition == 'neg_has_only_surround_noclass':\n",
    "    labels_to_sample = structures_to_sample + surround_noclass_labels_to_sample + ['noclass']\n",
    "elif neg_composition == 'neg_has_all_surround':\n",
    "    labels_to_sample = structures_to_sample + surround_positive_labels_to_sample + surround_noclass_labels_to_sample + ['noclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load training dataset.\n",
    "\n",
    "training_set_ids = map(int, str(classifier_properties['train_set_id']).split('/'))\n",
    "training_addresses = load_dataset_addresses(training_set_ids, labels_to_sample=labels_to_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_found = training_addresses.keys()\n",
    "structures_found = set([convert_to_original_name(l) for l in labels_found \n",
    "                        if convert_to_original_name(l) in labels_found]) - {'noclass'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_patches_pos = bp.unpack_ndarray_file('/tmp/patch_dataset_20/7N.bp')\n",
    "training_patches_neg = bp.unpack_ndarray_file('/tmp/patch_dataset_20/7N_surround_500_noclass.bp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training_patches_pos = extract_patches_given_locations_multiple_sections(training_addresses['7N'], \n",
    "#                                                                          location_or_grid_index='grid_index',\n",
    "#                                                                         version='cropped_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training_patches_neg = extract_patches_given_locations_multiple_sections(training_addresses['7N_surround_500_noclass'][:10], \n",
    "#                                                                          location_or_grid_index='grid_index',\n",
    "#                                                                         version='cropped_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_patches = np.concatenate([training_patches_pos, training_patches_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for structure in structures_found:\n",
    "\n",
    "#     print structure\n",
    "    \n",
    "#     #############################\n",
    "#     ## Define Positive Samples ##\n",
    "#     #############################\n",
    "    \n",
    "#     features_pos = training_features[structure]\n",
    "#     n_pos = len(features_pos)\n",
    "    \n",
    "#     #############################\n",
    "#     ## Define Negative Samples ##\n",
    "#     #############################\n",
    "    \n",
    "# #     if setting in [1, 3, 4, 5, 6, 7]:\n",
    "#     if neg_composition == 'neg_has_only_surround_noclass':\n",
    "#         neg_classes = [convert_to_surround_name(structure, margin=margin, suffix='noclass')]\n",
    "# #     elif setting in [2, 10, 23, 24, 25, 26]:\n",
    "#     elif neg_composition == 'neg_has_all_surround':\n",
    "#         neg_classes = [convert_to_surround_name(structure, margin=margin, suffix='noclass')]\n",
    "#         for surr_s in structures_found:\n",
    "#             c = convert_to_surround_name(structure, margin=margin, suffix=surr_s)\n",
    "#             if c in labels_found:\n",
    "#                 neg_classes.append(c)\n",
    "# #     elif setting in [8,9,11]:\n",
    "#     elif neg_composition == 'neg_has_everything_else':\n",
    "#         neg_classes = [structure + '_negative']\n",
    "#     else:\n",
    "#         raise Exception('neg_composition %s is not recognized.' % neg_composition)\n",
    "\n",
    "#     features_neg = np.concatenate([training_features[neg_class] for neg_class in neg_classes])\n",
    "        \n",
    "#     n_neg = len(features_neg)\n",
    "        \n",
    "#     ###########################################################################################\n",
    "\n",
    "#     train_data = np.r_[features_pos, features_neg]\n",
    "#     train_labels = np.r_[np.ones((features_pos.shape[0], )), \n",
    "#                          -np.ones((features_neg.shape[0], ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_size = 224\n",
    "half_size = patch_size/2\n",
    "stride = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "section_to_filename = metadata_cache['sections_to_filenames'][stack]\n",
    "\n",
    "image_width, image_height = metadata_cache['image_shape'][stack]\n",
    "grid_spec = (patch_size, stride, image_width, image_height)\n",
    "\n",
    "sample_locations = grid_parameters_to_sample_locations(grid_spec=grid_spec)\n",
    "\n",
    "sec = 180\n",
    "\n",
    "# Use grids only on mask.\n",
    "t = time.time()\n",
    "mask_tb = DataManager.load_thumbnail_mask_v2(stack=stack, section=sec)\n",
    "indices_roi = locate_patches_v2(grid_spec=grid_spec, mask_tb=mask_tb)\n",
    "sys.stderr.write('locate patches: %.2f seconds\\n' % (time.time() - t))       \n",
    "\n",
    "#         Use grids on the entire frame.\n",
    "#         indices_roi = range(len(sample_locations))\n",
    "\n",
    "n = len(indices_roi)\n",
    "sys.stderr.write('%d samples.\\n' % n)\n",
    "\n",
    "sample_locations_roi = sample_locations[indices_roi]\n",
    "\n",
    "t = time.time()\n",
    "img_fp = DataManager.get_image_filepath(stack=stack, section=sec, version='cropped_gray', resol='lossless')\n",
    "download_from_s3(img_fp)\n",
    "im = img_as_ubyte(imread(img_fp))\n",
    "sys.stderr.write('load image: %.2f seconds\\n' % (time.time() - t)) # ~ 35s\n",
    "\n",
    "#         t = time.time()\n",
    "#         sat = convert_to_saturation(im)\n",
    "#         del im\n",
    "#         sys.stderr.write('Convert to saturation: %.2f seconds\\n' % (time.time() - t)) # ~ 35s\n",
    "#         sat = imread(DataManager.get_image_filepath(stack=stack, section=sec, version='saturation'))\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "patches = np.array([im[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "                    for x, y in sample_locations_roi]) # n x 224 x 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_patches = np.array([im[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "                    for x, y in sample_locations_roi[:300]]) # n x 224 x 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_labels = np.zeros((training_patches.shape[0], 2))\n",
    "training_labels[:training_patches_pos.shape[0], 0] = 1\n",
    "training_labels[training_patches_pos.shape[0]:, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/tensorflow/blob/a5d8217c4ed90041bea2616c14a8ddcf11ec8c03/tensorflow/examples/tutorials/mnist/input_data.py#L92\n",
    "class DataSet(object):\n",
    "    \n",
    "    def __init__(self, images, labels):\n",
    "        \"\"\"Construct a DataSet. one_hot arg is used only if fake_data is true.\"\"\"\n",
    "\n",
    "\n",
    "        assert images.shape[0] == labels.shape[0], (\n",
    "          'images.shape: %s labels.shape: %s' % (images.shape,\n",
    "                                                 labels.shape))\n",
    "        self._num_examples = images.shape[0]\n",
    "\n",
    "        # Convert shape from [num examples, rows, columns, depth]\n",
    "        # to [num examples, rows*columns] (assuming depth == 1)\n",
    "        #assert images.shape[3] == 1\n",
    "        images = images.reshape(images.shape[0],\n",
    "                              images.shape[1] * images.shape[2])\n",
    "        # Convert from [0, 255] -> [0.0, 1.0].\n",
    "        images = images.astype(np.float32)\n",
    "        images = images / 255.\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "\n",
    "    def next_batch(self, batch_size, fake_data=False):\n",
    "\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "        return self._images[start:end], self._labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_set = DataSet(training_patches[:128], training_labels[:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "learning_rate = 0.1\n",
    "training_iters = 10000000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "num_epochs = 100\n",
    "\n",
    "# # Network Parameters\n",
    "# n_input = 224*224 # MNIST data input (img shape: 28*28)\n",
    "dropout = 0.75 # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/how_tos/reading_data/fully_connected_preloaded_var.py#L45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "# Input data\n",
    "    images_initializer = tf.placeholder(dtype=data_set.images.dtype,\n",
    "                                        shape=data_set.images.shape)\n",
    "#                                         shape=[None, 784])\n",
    "    labels_initializer = tf.placeholder(dtype=data_set.labels.dtype,\n",
    "                                        shape=data_set.labels.shape)\n",
    "#                                          shape=[None, 2])\n",
    "    input_images = tf.Variable(images_initializer, trainable=False, collections=[])\n",
    "    input_labels = tf.Variable(labels_initializer, trainable=False, collections=[])\n",
    "\n",
    "    image, label = tf.train.slice_input_producer(\n",
    "      [input_images, input_labels], num_epochs=num_epochs)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    images, labels = tf.train.batch(\n",
    "      [image, label], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 64 # 1st layer num features\n",
    "n_hidden_2 = 16 # 2nd layer num features\n",
    "n_input = 224 * 224 # MNIST data input (img shape: 28*28)\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([n_input])),\n",
    "}\n",
    "\n",
    "# Building the encoder\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "                                   biases['encoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
    "                                   biases['encoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
    "                                   biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
    "                                   biases['decoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "# Construct model\n",
    "encoder_op = encoder(images)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = images\n",
    "\n",
    "# Define loss and optimizer, minimize the squared error\n",
    "cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(input_images.initializer,\n",
    "             feed_dict={images_initializer: data_set.images})\n",
    "    sess.run(input_labels.initializer,\n",
    "             feed_dict={labels_initializer: data_set.labels})\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "#         batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x, batch_y = data_set.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={images: batch_x})\n",
    "#         sess.run(optimizer, feed_dict={images: batch_x, labels: batch_y,\n",
    "#                                        keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "#             loss, acc = sess.run([cost, accuracy], feed_dict={images: batch_x,\n",
    "#                                                               keep_prob: 1.})\n",
    "#             print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "#                   \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "#                   \"{:.5f}\".format(acc)\n",
    "\n",
    "            print \"Epoch: %04d, cost=%.9f\" % (step + 1, c)\n",
    "                \n",
    "            # Applying encode and decode over test set\n",
    "            encode_decode = sess.run(\n",
    "                y_pred, feed_dict={images: data_set.images[:128]})\n",
    "\n",
    "            display_images_in_grids([np.reshape(encode_decode[i], (224, 224)) for i in range(10)], nc=10, \n",
    "                                    cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "        step += 1\n",
    "    print \"Optimization Finished!\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_images_in_grids([np.reshape(encode_decode[i], (224, 224)) for i in range(10)], nc=10, cmap=plt.cm.gray,\n",
    "                       vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_images_in_grids([np.reshape(data_set.images[i], (224, 224)) for i in range(10)], nc=10, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def simplified_vgg(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 224, 224, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=4)\n",
    "    \n",
    "    # Convolution Layer\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv3 = maxpool2d(conv3, k=4)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wc3': tf.Variable(tf.random_normal([5, 5, 64, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bc3': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = simplified_vgg(images, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(input_images.initializer,\n",
    "             feed_dict={images_initializer: data_set.images})\n",
    "    sess.run(input_labels.initializer,\n",
    "             feed_dict={labels_initializer: data_set.labels})\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "#         batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x, batch_y = data_set.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={images: batch_x, labels: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={images: batch_x,\n",
    "                                                              labels: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc)\n",
    "        step += 1\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print \"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={images: data_set.images[:128],\n",
    "                                      labels: data_set.labels[:128],\n",
    "                                      keep_prob: 1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
