{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuncong/MouseBrainAtlas/src/utilities/utilities2015.py:2: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-ddb6eb490732>\", line 6, in <module>\n",
      "    get_ipython().magic(u'matplotlib inline')\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2160, in magic\n",
      "    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2081, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-105>\", line 2, in matplotlib\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/magic.py\", line 188, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/magics/pylab.py\", line 100, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/pylabtools.py\", line 308, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py\", line 1305, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Precision WorkStation\n",
      "{'DEMO998': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "No anchor.txt is found. Seems we are using the operation ini to provide anchor. Try to load operation ini.\n",
      "No anchor.txt is found. Seems we are using the operation ini to provide anchor. Try to load operation ini.\n",
      "No vtk\n",
      "No anchor.txt is found. Seems we are using the operation ini to provide anchor. Try to load operation ini.\n",
      "Seems you are using operation INIs to provide cropbox.\n",
      "No anchor.txt is found. Seems we are using the operation ini to provide anchor. Try to load operation ini.\n",
      "Seems you are using operation INIs to provide cropbox.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from registration_utilities import *\n",
    "from annotation_utilities import *\n",
    "from metadata import *\n",
    "from data_manager import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_structure_contours_from_structure_volumes_v3(volumes, stack, sections, \n",
    "                                                     resolution, level, sample_every=1,\n",
    "                                                    use_unsided_name_as_key=False):\n",
    "    \"\"\"\n",
    "    Re-section atlas volumes and obtain structure contours on each section.\n",
    "    Resolution of output contours are in volume resolution.\n",
    "    v3 supports multiple levels.\n",
    "\n",
    "    Args:\n",
    "        volumes (dict of (3D array, 3-tuple)): {structure: (volume, origin_wrt_wholebrain)}. volume is a 3d array of probability values.\n",
    "        sections (list of int):\n",
    "        resolution (int): resolution of input volumes.\n",
    "        level (float or dict or dict of list): the cut-off probability at which surfaces are generated from probabilistic volumes. Default is 0.5.\n",
    "        sample_every (int): how sparse to sample contour vertices.\n",
    "\n",
    "    Returns:\n",
    "        Dict {section: {name_s: contour vertices wrt_alignedBrainstemCrop_rawResol}}.\n",
    "    \"\"\"\n",
    "\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    structure_contours_wrt_alignedBrainstemCrop_rawResol = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    converter = CoordinatesConverter(stack=stack, section_list=metadata_cache['sections_to_filenames'][stack].keys())\n",
    "\n",
    "    converter.register_new_resolution('structure_volume', resol_um=convert_resolution_string_to_um(resolution=resolution, stack=stack))\n",
    "    converter.register_new_resolution('image', resol_um=convert_resolution_string_to_um(resolution='raw', stack=stack))\n",
    "    \n",
    "    for name_s, (structure_volume_volResol, origin_wrt_wholebrain_volResol) in volumes.iteritems():\n",
    "\n",
    "        converter.derive_three_view_frames(name_s, \n",
    "        origin_wrt_wholebrain_um=convert_resolution_string_to_um(resolution=resolution, stack=stack) * origin_wrt_wholebrain_volResol,\n",
    "        zdim_um=convert_resolution_string_to_um(resolution=resolution, stack=stack) * structure_volume_volResol.shape[2])\n",
    "\n",
    "        positions_of_all_sections_wrt_structureVolume = converter.convert_frame_and_resolution(\n",
    "        p=np.array(sections)[:,None],\n",
    "        in_wrt=('wholebrain', 'sagittal'), in_resolution='section',\n",
    "        out_wrt=(name_s, 'sagittal'), out_resolution='structure_volume')[..., 2].flatten()\n",
    "            \n",
    "        structure_ddim = structure_volume_volResol.shape[2]\n",
    "        \n",
    "        valid_mask = (positions_of_all_sections_wrt_structureVolume >= 0) & (positions_of_all_sections_wrt_structureVolume < structure_ddim)\n",
    "        if np.count_nonzero(valid_mask) == 0:\n",
    "#             sys.stderr.write(\"%s, valid_mask is empty.\\n\" % name_s)\n",
    "            continue\n",
    "\n",
    "        positions_of_all_sections_wrt_structureVolume = positions_of_all_sections_wrt_structureVolume[valid_mask]\n",
    "        positions_of_all_sections_wrt_structureVolume = np.round(positions_of_all_sections_wrt_structureVolume).astype(np.int)\n",
    "        \n",
    "        if isinstance(level, dict):\n",
    "            level_this_structure = level[name_s]\n",
    "        else:\n",
    "            level_this_structure = level\n",
    "\n",
    "        if isinstance(level_this_structure, float):\n",
    "            level_this_structure = [level_this_structure]\n",
    "                        \n",
    "        for one_level in level_this_structure:\n",
    "\n",
    "            contour_2d_wrt_structureVolume_sectionPositions_volResol = \\\n",
    "            find_contour_points_3d(structure_volume_volResol >= one_level,\n",
    "                                    along_direction='sagittal',\n",
    "                                    sample_every=sample_every,\n",
    "                                    positions=positions_of_all_sections_wrt_structureVolume)\n",
    "\n",
    "            for d_wrt_structureVolume, cnt_uv_wrt_structureVolume in contour_2d_wrt_structureVolume_sectionPositions_volResol.iteritems():\n",
    "\n",
    "                contour_3d_wrt_structureVolume_volResol = np.column_stack([cnt_uv_wrt_structureVolume, np.ones((len(cnt_uv_wrt_structureVolume),)) * d_wrt_structureVolume])\n",
    "\n",
    "    #             contour_3d_wrt_wholebrain_uv_rawResol_section = converter.convert_frame_and_resolution(\n",
    "    #                 p=contour_3d_wrt_structureVolume_volResol,\n",
    "    #                 in_wrt=(name_s, 'sagittal'), in_resolution='structure_volume',\n",
    "    #                 out_wrt=('wholebrain', 'sagittal'), out_resolution='image_image_section')\n",
    "\n",
    "                contour_3d_wrt_alignedBrainstemCrop_uv_rawResol_section = converter.convert_frame_and_resolution(\n",
    "                    p=contour_3d_wrt_structureVolume_volResol,\n",
    "                    in_wrt=(name_s, 'sagittal'), in_resolution='structure_volume',\n",
    "                    out_wrt=('wholebrainXYcropped', 'sagittal'), out_resolution='image_image_section')\n",
    "\n",
    "                assert len(np.unique(contour_3d_wrt_alignedBrainstemCrop_uv_rawResol_section[:,2])) == 1\n",
    "                sec = int(contour_3d_wrt_alignedBrainstemCrop_uv_rawResol_section[0,2])\n",
    "\n",
    "                if use_unsided_name_as_key:\n",
    "                    name = convert_to_unsided_label(name_s)\n",
    "                else:\n",
    "                    name = name_s\n",
    "\n",
    "                structure_contours_wrt_alignedBrainstemCrop_rawResol[sec][name][one_level] = contour_3d_wrt_alignedBrainstemCrop_uv_rawResol_section[..., :2]\n",
    "        \n",
    "    return structure_contours_wrt_alignedBrainstemCrop_rawResol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_structure_alignment_spec = load_json('../../demo/demo_visualization_per_structure_alignment_spec.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simpleGlobal_alignment_spec = load_json('../../demo/demo_visualization_global_alignment_spec.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structure_list = ['12N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "section_margin_um = 1000.\n",
    "section_margin = int(section_margin_um / SECTION_THICKNESS)\n",
    "\n",
    "stack = 'DEMO998'\n",
    "# stack = brain_f_spec['name']\n",
    "# valid_secmin = np.min(metadata_cache['valid_sections'][stack])\n",
    "# valid_secmax = np.max(metadata_cache['valid_sections'][stack])\n",
    "valid_secmin = 1\n",
    "valid_secmax = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto_contours_all_sec_all_structures_all_levels = defaultdict(lambda: defaultdict(dict))\n",
    "simple_global_contours_all_sec_all_structures_all_levels = defaultdict(lambda: defaultdict(dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No anchor.txt is found. Seems we are using the operation ini to provide anchor. Try to load operation ini.\n",
      "Seems you are using operation INIs to provide cropbox.\n",
      "2 contours of reconstructed volume is found at position 111 ([45, 1]). Use the longest one.\n",
      "3 contours of reconstructed volume is found at position 125 ([16, 1, 1]). Use the longest one.\n",
      "2 contours of reconstructed volume is found at position 49 ([36, 3]). Use the longest one.\n",
      "2 contours of reconstructed volume is found at position 55 ([32, 7]). Use the longest one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302]\n",
      "(100, 137, 146) [1100.  397.  414.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No anchor.txt is found. Seems we are using the operation ini to provide anchor. Try to load operation ini.\n",
      "Seems you are using operation INIs to provide cropbox.\n"
     ]
    }
   ],
   "source": [
    "for structure_m in structure_list:\n",
    "\n",
    "    ####################################################\n",
    "    \n",
    "    local_alignment_spec = per_structure_alignment_spec[structure_m]\n",
    "    \n",
    "    vo = DataManager.load_transformed_volume_v2(alignment_spec=local_alignment_spec, \n",
    "                                                return_origin_instead_of_bbox=True,\n",
    "                                               structure=structure_m)\n",
    "\n",
    "    # prep2 because at end of get_structure_contours_from_structure_volumes_v2 we used wholebrainXYcropped\n",
    "    registered_atlas_structures_wrt_wholebrainXYcropped_xysecTwoCorners_atlasResol = \\\n",
    "    load_json(os.path.join(DATA_ROOTDIR, 'CSHL_simple_global_registration', stack + '_registered_atlas_structures_wrt_wholebrainXYcropped_xysecTwoCorners.json'))\n",
    "\n",
    "    (_, _, secmin), (_, _, secmax) = registered_atlas_structures_wrt_wholebrainXYcropped_xysecTwoCorners_atlasResol[structure_m]\n",
    "    print secmin, secmax\n",
    "\n",
    "    atlas_structures_wrt_wholebrainXYcropped_sections = \\\n",
    "    range(max(secmin - section_margin, valid_secmin), min(secmax + 1 + section_margin, valid_secmax) + 1)\n",
    "    \n",
    "#     atlas_structures_wrt_wholebrainWithMargin_sections = \\\n",
    "#     range(max(secmin - section_margin, valid_secmin), min(secmax + 1 + section_margin, valid_secmax) + 1)\n",
    "\n",
    "    levels = [0.1, 0.25, 0.5, 0.75, 0.99]\n",
    "\n",
    "#     auto_contours_all_sections_one_structure_all_levels = \\\n",
    "#     get_structure_contours_from_structure_volumes_v3(volumes={structure_m: vo}, stack=stack, \n",
    "#                                                      sections=atlas_structures_wrt_wholebrainWithMargin_sections,\n",
    "#                                                     resolution='10.0um', level=levels, sample_every=5)\n",
    "\n",
    "#     print atlas_structures_wrt_wholebrainWithMargin_sections\n",
    "\n",
    "    auto_contours_all_sections_one_structure_all_levels = \\\n",
    "    get_structure_contours_from_structure_volumes_v3(volumes={structure_m: vo}, stack=stack, \n",
    "                                                     sections=atlas_structures_wrt_wholebrainXYcropped_sections,\n",
    "                                                    resolution='10.0um', level=levels, sample_every=5)\n",
    "\n",
    "    print atlas_structures_wrt_wholebrainXYcropped_sections\n",
    "    print vo[0].shape, vo[1]\n",
    "\n",
    "    for sec, contours_one_structure_all_levels in sorted(auto_contours_all_sections_one_structure_all_levels.items()):\n",
    "        if not is_invalid(sec=sec, stack=stack):\n",
    "            for name_s, cnt_all_levels in contours_one_structure_all_levels.items():\n",
    "                for level, cnt in cnt_all_levels.iteritems():\n",
    "                    auto_contours_all_sec_all_structures_all_levels[sec][name_s][level] = cnt.astype(np.int)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    simpleGlobal_vo_wrt_wholebrain = DataManager.load_transformed_volume_v2(alignment_spec=simpleGlobal_alignment_spec, \n",
    "                                                             return_origin_instead_of_bbox=True,\n",
    "                                                            structure=structure_m)\n",
    "\n",
    "    simpleGlobal_contours_all_sections_one_structure_all_levels = \\\n",
    "    get_structure_contours_from_structure_volumes_v3(volumes={structure_m: simpleGlobal_vo_wrt_wholebrain}, stack=stack, \n",
    "                                                     sections=atlas_structures_wrt_wholebrainXYcropped_sections,\n",
    "                                                    resolution='10.0um', level=levels, sample_every=5)\n",
    "    \n",
    "    for sec, contours_one_structure_all_levels in sorted(simpleGlobal_contours_all_sections_one_structure_all_levels.items()):\n",
    "        if not is_invalid(sec=sec, stack=stack):\n",
    "            for name_s, cnt_all_levels in contours_one_structure_all_levels.items():\n",
    "                for level, cnt in cnt_all_levels.iteritems():\n",
    "                    simple_global_contours_all_sec_all_structures_all_levels[sec][name_s][level] = cnt.astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to load /home/yuncong/MouseBrainAtlas/demo/demo_data/CSHL_data_processed/DEMO998/DEMO998_prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg/MD662&661-F81-2017.06.06-12.44.40_MD661_2_0242_prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg.jpg\n"
     ]
    }
   ],
   "source": [
    "for sec in [225]:\n",
    "\n",
    "\n",
    "    for version in ['NtbNormalizedAdaptiveInvertedGammaJpeg']:\n",
    "#         for version in ['grayJpeg']:\n",
    "#         for version in ['NtbNormalizedAdaptiveInvertedGammaJpeg', 'CHATJpeg']:\n",
    "        \n",
    "        try:\n",
    "            img = DataManager.load_image_v2(stack=stack, prep_id=2, resol='raw', version=version, section=sec)\n",
    "\n",
    "            viz = gray2rgb(img)\n",
    "\n",
    "            # Draw the locally aligned structure contours in COLOR\n",
    "            for name_s, cnt_all_levels in auto_contours_all_sec_all_structures_all_levels[sec].iteritems():\n",
    "\n",
    "                for level, cnt in cnt_all_levels.iteritems():\n",
    "                    cv2.polylines(viz, [cnt.astype(np.int)], isClosed=True, \n",
    "                                  color=LEVEL_TO_COLOR_LINE[level], thickness=10)\n",
    "            \n",
    "            # Draw the simple globally aligned structure contours in WHITE\n",
    "            for name_s, cnt_all_levels in simple_global_contours_all_sec_all_structures_all_levels[sec].iteritems():\n",
    "\n",
    "                for level, cnt in cnt_all_levels.iteritems():\n",
    "                    cv2.polylines(viz, [cnt.astype(np.int)], isClosed=True, \n",
    "                                  color=(255,255,255), \n",
    "                                  thickness=10)\n",
    "\n",
    "    # #             # Add CHAT contour\n",
    "    #             if sec in chat_contours_all_sections_all_structures_all_levels:\n",
    "    #                 chat_cnt = chat_contours_all_sections_all_structures_all_levels[sec][name_s][.5]\n",
    "    #                 cv2.polylines(viz, [chat_cnt.astype(np.int)], isClosed=True, color=(255,255,255), thickness=20)\n",
    "\n",
    "    #             fp = os.path.join('/home/yuncong/' + stack + '_atlas_aligned_multilevel_all_structures', version, stack + '_' + version + '_' + ('%03d' % sec) + '.jpg')\n",
    "    #             print fp\n",
    "    #             create_parent_dir_if_not_exists(fp)\n",
    "    #             imsave(fp, viz)\n",
    "\n",
    "#             fp = os.path.join(ROOT_DIR, 'CSHL_registration_visualization', \n",
    "#                               stack + '_atlas_aligned_multilevel_down16_all_structures', \n",
    "#                               version, stack + '_' + version + '_' + ('%03d' % sec) + '.jpg')    \n",
    "#             create_parent_dir_if_not_exists(fp)\n",
    "#             imsave(fp, viz[::16, ::16])\n",
    "#  #           upload_to_s3(fp)\n",
    "            \n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='tmp.jpg' target='_blank'>tmp.jpg</a><br>"
      ],
      "text/plain": [
       "/home/yuncong/MouseBrainAtlas/src/registration/tmp.jpg"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_image(viz[::16, ::16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
