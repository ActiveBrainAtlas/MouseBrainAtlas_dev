{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume_dir = '/home/yuncong/csd395/CSHL_volumes/'\n",
    "\n",
    "labels_twoSides = []\n",
    "labels_twoSides_indices = {}\n",
    "with open(volume_dir+'/MD589/volume_MD589_annotation_withOuterContour_labelIndices.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        name, index = line.split()\n",
    "        labels_twoSides.append(name)\n",
    "        labels_twoSides_indices[name] = int(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelMap_sidedToUnsided = {name: name if '_' not in name else name[:-2] for name in labels_twoSides_indices.keys()}\n",
    "labels_unsided = ['BackG'] + sorted(set(labelMap_sidedToUnsided.values()) - {'BackG', 'outerContour'}) + ['outerContour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838 459 534\n"
     ]
    }
   ],
   "source": [
    "atlasProjected_volume = bp.unpack_ndarray_file(os.path.join(volume_dir, 'MD589/volume_MD589_annotation_withOuterContour.bp'))\n",
    "atlas_ydim, atlas_xdim, atlas_zdim = atlasProjected_volume.shape\n",
    "print atlas_xdim, atlas_ydim, atlas_zdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.11578392982 seconds\n"
     ]
    }
   ],
   "source": [
    "def parallel_where(l):\n",
    "    w = np.where(atlasProjected_volume == l)\n",
    "    return np.c_[w[1], w[0], w[2]]\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "atlas_nzs = Parallel(n_jobs=16)(delayed(parallel_where)(labels_twoSides_indices[name]) \n",
    "                                for name in labels_twoSides[1:])\n",
    "\n",
    "atlas_nzs = dict(zip(labels_twoSides[1:], atlas_nzs))\n",
    "\n",
    "print time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atlas_xmin, atlas_ymin, atlas_zmin = np.min([np.min(nzs, axis=1) for nzs in atlas_nzs.itervalues()], axis=0)\n",
    "atlas_xmax, atlas_ymax, atlas_zmax = np.max([np.max(nzs, axis=1) for nzs in atlas_nzs.itervalues()], axis=0)\n",
    "print atlas_xmin, atlas_xmax, atlas_ymin, atlas_ymax, atlas_zmin, atlas_zmax\n",
    "\n",
    "atlas_centroid = np.array([.5*atlas_xmin+.5*atlas_xmax, .5*atlas_ymin+.5*atlas_ymax, .5*atlas_zmin+.5*atlas_zmax])\n",
    "print atlas_centroid\n",
    "\n",
    "atlas_cx, atlas_cy, atlas_cz = atlas_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsample_factor = 16\n",
    "\n",
    "section_thickness = 20 # in um\n",
    "xy_pixel_distance_lossless = 0.46\n",
    "xy_pixel_distance_tb = xy_pixel_distance_lossless * 32 # in um, thumbnail\n",
    "# factor = section_thickness/xy_pixel_distance_lossless\n",
    "\n",
    "xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "z_xy_ratio_downsampled = section_thickness / xy_pixel_distance_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlasAlignOptLogs_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignOptLogs'\n",
    "if not os.path.exists(atlasAlignOptLogs_dir):\n",
    "    os.makedirs(atlasAlignOptLogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlasAlignParams_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignParams'\n",
    "if not os.path.exists(atlasAlignParams_dir):\n",
    "    os.makedirs(atlasAlignParams_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotationsViz_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_annotaionsPojectedViz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD594'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(atlasAlignParams_dir + '/%(stack)s/%(stack)s_3dAlignParams.txt' % {'stack': stack}, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "T_final = map(float, lines[1].strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atlas_pts_centered = {}\n",
    "for l in labels_twoSides[1:]:\n",
    "    atlas_pts_centered[l] = atlas_nzs[l] - atlas_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "section_bs_begin, section_bs_end = section_range_lookup[stack]\n",
    "print section_bs_begin, section_bs_end\n",
    "\n",
    "# (volume_xmin, volume_xmax, volume_ymin, volume_ymax, volume_zmin, volume_zmax) = \\\n",
    "# np.loadtxt(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_limits.txt' % {'stack': stack}), dtype=np.int)\n",
    "\n",
    "# map_z_to_section = {}\n",
    "# for s in range(section_bs_begin, section_bs_end+1):\n",
    "#     for z in range(int(z_xy_ratio_downsampled*s) - volume_zmin, int(z_xy_ratio_downsampled*(s+1)) - volume_zmin + 1):\n",
    "#         map_z_to_section[z] = s\n",
    "\n",
    "# global volume2_allLabels\n",
    "# volume2_allLabels = {}\n",
    "\n",
    "# for l in labels_unsided[1:]:\n",
    "\n",
    "#     print l\n",
    "\n",
    "#     volume2 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_%(label)s.bp' % \\\n",
    "#                                                   {'stack': stack, 'label': l}))\n",
    "\n",
    "#     volume2_cropped = volume2[volume_ymin:volume_ymax+1, volume_xmin:volume_xmax+1]\n",
    "#     # copy is important, because then you can delete the large array\n",
    "\n",
    "#     volume2_allLabels[l] = volume2_cropped.copy()\n",
    "\n",
    "#     del volume2, volume2_cropped\n",
    "\n",
    "test_ydim, test_xdim, test_zdim = volume2_allLabels.values()[0].shape\n",
    "test_centroid = (.5*test_xdim, .5*test_ydim, .5*test_ydim)\n",
    "\n",
    "print test_xdim, test_ydim, test_zdim\n",
    "print test_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d2Sdxyz2 = {}\n",
    "\n",
    "for l in labels[1:-1]:\n",
    "    \n",
    "    print l\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    gxx = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gxx.hdf' % {'stack': stack, 'lab': l}).astype(np.float16)\n",
    "    gxy = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gxy.hdf' % {'stack': stack, 'lab': l}).astype(np.float16)\n",
    "    gxz = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gxz.hdf' % {'stack': stack, 'lab': l}).astype(np.float16)\n",
    "    gyx = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gyx.hdf' % {'stack': stack, 'lab': l}).astype(np.float16)\n",
    "    gyy = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gyy.hdf' % {'stack': stack, 'lab': l}).astype(np.float16)\n",
    "    gyz = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gyz.hdf' % {'stack': stack, 'lab': l}).astype(np.float16)\n",
    "    gzx = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gzx.hdf' % {'stack': stack, 'lab': l}).astype(np.float16)\n",
    "    gzy = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gzy.hdf' % {'stack': stack, 'lab': l}).astype(np.float16)\n",
    "    gzz = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gzz.hdf' % {'stack': stack, 'lab': l}).astype(np.float16)\n",
    "    \n",
    "    print time.time() - t\n",
    "    \n",
    "    d2Sdxyz2[l] = [gxx, gxy, gxz, gyx, gyy, gyz, gzx, gzy, gzz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_score_hessian(T):\n",
    "    \n",
    "#     Tm = np.reshape(T, (3,4))\n",
    "#     tx, ty, tz = Tm[:, 3]\n",
    "#     A = Tm[:, :3]\n",
    "\n",
    "    d2MdT2 = np.zeros((12, 12))\n",
    "    \n",
    "#     for l in range(1, n_labels):\n",
    "    for l in labels_twoSides[1:-1]:\n",
    "        \n",
    "        name_unsided = labelMap_sidedToUnsided[l]\n",
    "        \n",
    "        pts_prime = transform_points(T, pts_centered=atlas_pts_centered[l], c_prime=test_centroid).astype(np.int)\n",
    "            \n",
    "        xs_prime, ys_prime, zs_prime = pts_prime.T\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "\n",
    "        if np.count_nonzero(valid) > 0:\n",
    "\n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            dxs, dys, dzs = atlas_pts_centered[l][valid].T\n",
    "\n",
    "            Sxx_full, Sxy_full, Sxz_full, Syx_full, Syy_full, Syz_full, Szx_full, Szy_full, Szz_full = d2Sdxyz2[name_unsided]\n",
    "            Sxx = Sxx_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sxy = Sxy_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sxz = Sxz_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Syx = Syx_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Syy = Syy_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Syz = Syz_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Szx = Szx_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Szy = Szy_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Szz = Szz_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "\n",
    "            rx = np.c_[Sxx*dxs, Sxx*dys, Sxx*dzs, Sxx, Sxy*dxs, Sxy*dys, Sxy*dzs, Sxy, Sxz*dxs, Sxz*dys, Sxz*dzs, Sxz]\n",
    "            ry = np.c_[Syx*dxs, Syx*dys, Syx*dzs, Syx, Syy*dxs, Syy*dys, Syy*dzs, Syy, Syz*dxs, Syz*dys, Syz*dzs, Syz]\n",
    "            rz = np.c_[Szx*dxs, Szx*dys, Szx*dzs, Szx, Szy*dxs, Szy*dys, Szy*dzs, Szy, Szz*dxs, Szz*dys, Szz*dzs, Szz]\n",
    "            r1 = (rx*dxs[:,None]).sum(axis=0)\n",
    "            r2 = (rx*dys[:,None]).sum(axis=0)\n",
    "            r3 = (rx*dzs[:,None]).sum(axis=0)\n",
    "            r4 = rx.sum(axis=0)\n",
    "            r5 = (ry*dxs[:,None]).sum(axis=0)\n",
    "            r6 = (ry*dys[:,None]).sum(axis=0)\n",
    "            r7 = (ry*dzs[:,None]).sum(axis=0)\n",
    "            r8 = ry.sum(axis=0)\n",
    "            r9 = (rz*dxs[:,None]).sum(axis=0)\n",
    "            r10 = (rz*dys[:,None]).sum(axis=0)\n",
    "            r11 = (rz*dzs[:,None]).sum(axis=0)\n",
    "            r12 = rz.sum(axis=0)\n",
    "            \n",
    "            d2MdT2_l = np.vstack([r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12])\n",
    "        \n",
    "            del xs_prime_valid, ys_prime_valid, zs_prime_valid\n",
    "            del dxs, dys, dzs\n",
    "            del Sxx_full, Sxy_full, Sxz_full, Syx_full, Syy_full, Syz_full, Szx_full, Szy_full, Szz_full\n",
    "            del Sxx, Sxy, Sxz, Syx, Syy, Syz, Szx, Szy, Szz\n",
    "            del rx, ry, rz\n",
    "            del r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12\n",
    "            \n",
    "        \n",
    "            d2MdT2 += d2MdT2_l\n",
    "        \n",
    "            del d2MdT2_l\n",
    "        del xs_prime, ys_prime, zs_prime, valid\n",
    "    \n",
    "    return d2MdT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H = compute_score_hessian(T_final)\n",
    "plt.stem(range(12), H.diagonal());\n",
    "print 'mean curvature:', np.sum(H.diagonal())\n",
    "print 'mean curvature related to translations:', np.sum(H.diagonal()[[3,7,11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(H, cmap=plt.cm.RdBu, vmin=-1e5, vmax=1e5);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check hessians at neighborhoods of the optimum\n",
    "for _ in range(10):\n",
    "    Hr = compute_score_hessian(np.array(T_final) + [0,0,0,np.random.randint(-10,10),\n",
    "                                                   0,0,0,np.random.randint(-10,10),\n",
    "                                                   0,0,0,np.random.randint(-10,10)])\n",
    "    print 'mean curvature:', np.sum(Hr.diagonal())\n",
    "    print 'mean curvature related to translations:', np.sum(Hr.diagonal()[[3,7,11]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
