{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from_fp = 'mousebrainatlas-rawdata/CSHL_volumes/atlasV6/atlasV6_10.0um_scoreVolume/score_volumes/'\n",
    "to_fp = '/media/alexn/BstemAtlasDataBackup/demo/CSHL_volumes/atlasV6/atlasV6_10.0um_scoreVolume/score_volumes/'\n",
    "include_only = 'atlasV6_10.0um_scoreVolume_12N*'\n",
    "execute_command('aws s3 cp --recursive \\\"s3://%(from_fp)s\\\" \\\"%(to_fp)s\\\" --exclude \\\"*\\\" --include \\\"%(include)s\\\"'\\\n",
    "                % dict(from_fp=from_fp, to_fp=to_fp, include=include_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "\n",
    "# %reload_ext : Reloads an IPython extension by its module name.\n",
    "%reload_ext autoreload\n",
    "# %autoreload 2 : Reloads all modules (except those excluded by %aimport)  \n",
    "#  every time before executing the Python code typed.\n",
    "%autoreload 2\n",
    "\n",
    "# %TEXT : code in this format is called a \"magic function\" \n",
    "#  https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline/43028034\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Sets backend of matplotlib to the 'inline' backend\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *\n",
    "\n",
    "\n",
    "stack = 'MD662'\n",
    "print('testing metadata: ',metadata_cache['valid_filenames_all'][stack][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download files from S3\n",
    "# Not necessary if files are not on S3\n",
    "! aws s3 cp --recursive --force-glacier-transfer \\\n",
    "    \"s3://mousebrainatlas-rawdata/CSHL_data/MD662\" \"/shared/CSHL_data/MD662\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscillaneous Code\n",
    "#### Function to detect where you are at running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BAD FILE LOCATOR\n",
    "# Automatically tells where in the code you are\n",
    "\n",
    "# 1) raw -> raw_Ntb: extract_channel\n",
    "# 2) raw_Ntb -> thumbnail_Ntb: rescale\n",
    "# 3) thumbnail_Ntb -> thumbnail_NtbNormalized: normalize_intensity\n",
    "# 4) Compute transforms using thumbnail_NtbNormalized: align + compose\n",
    "# 5) Supply prep1_thumbnail_mask\n",
    "# 6) prep1_thumbnail_mask -> thumbnail_mask: warp\n",
    "# 7) raw_Ntb -> raw_NtbNormalizedAdaptiveInvertedGamma: brightness_correction\n",
    "# 8) Compute prep5 (alignedWithMargin) cropping box based on prep1_thumbnail_mask\n",
    "# 9) raw_NtbNormalizedAdaptiveInvertedGamma -> prep5_raw_NtbNormalizedAdaptiveInvertedGamma: align + crop\n",
    "# 10) thumbnail_NtbNormalized -> prep5_thumbnail_NtbNormalized: align + crop\n",
    "# 11) prep5_raw_NtbNormalizedAdaptiveInvertedGamma -> prep5_thumbnail_NtbNormalizedAdaptiveInvertedGamma: rescale\n",
    "# 12) Specify prep2 (alignedBrainstemCrop) cropping box\n",
    "# 13) prep5_raw_NtbNormalizedAdaptiveInvertedGamma -> prep2_raw_NtbNormalizedAdaptiveInvertedGamma: crop\n",
    "# 14) prep2_raw_NtbNormalizedAdaptiveInvertedGamma -> prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg: compress_jpeg\n",
    "\n",
    "# np.setdiff1d(list1,list2) # Get difference between two lists\n",
    "# metadata_cache['valid_filenames_all'][stack]  # To get all valid filenames\n",
    "\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "\n",
    "def where_am_i():\n",
    "    '''\n",
    "    where_am_i will iterate through each of the 14 steps of preprocessing, checking that ALL output files \n",
    "    have been generated sucessfully. For any stage where files are missing or corrupted, this function will \n",
    "    return a list of the filepaths & filenames of the images that are not in the output.\n",
    "    where_am_i() returns [bad_fp_list, bad_file_list].\n",
    "    '''\n",
    "    \n",
    "    # Throws an error if you don't set Max Pixels to around 2 Billion (yikes)\n",
    "    Image.MAX_IMAGE_PIXELS = 2000000000\n",
    "    # Iterates through every possible filename as defined in metadata_cache\n",
    "    #                                           stack must be defined\n",
    "    bad_fp_list = [] # Full filePaths\n",
    "    bad_file_list = [] # FileNames\n",
    "    \n",
    "    #   Dic = {'step#': [prep_id, resol, version]}\n",
    "    stepDic = {'1':[None,'raw','Ntb'], '2':[None,'thumbnail','Ntb'], '3':[None,'thumbnail','NtbNormalized'],\\\n",
    "               '4':[None,'???','???'], '5':[1,'thumbnail','mask'], '6':[None,'???','???'], \\\n",
    "               '7':[None,'raw','NtbNormalizedAdaptiveInvertedGamma'], '8':[5,'thumbnail','mask'], \\\n",
    "               '9':[5,'raw','NtbNormalizedAdaptiveInvertedGamma'], '10':[5,'thumbnail','NtbNormalized'], \\\n",
    "               '11':[5,'thumbnail','NtbNormalizedAdaptiveInvertedGamma']}\n",
    "\n",
    "    \n",
    "    # For checking each individual step of the pipeline as outlined above\n",
    "    for step in range (2,12):\n",
    "        stepStr = str(step)\n",
    "        stepCompleted = True\n",
    "        \n",
    "        print 'Checking for completion of step '+stepStr\n",
    "        t = time.time()\n",
    "        \n",
    "        if stepDic[stepStr][1]=='???':\n",
    "                stepCompleted = False\n",
    "                print 'Output files unknown. No idea.'\n",
    "                print ''\n",
    "                continue\n",
    "        \n",
    "        for fn in metadata_cache['valid_filenames_all'][stack]:\n",
    "            \n",
    "            # Record the filepath from every filename + info from the \"step dictionary\"\n",
    "            fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=stepDic[stepStr][0], \\\n",
    "                                     resol=stepDic[stepStr][1], version=stepDic[stepStr][2], fn=fn)\n",
    "            \n",
    "            fp_to_test = fp\n",
    "            try:\n",
    "                img = Image.open(fp_to_test) # open the image file\n",
    "                img.verify() # verify that it is, in fact an uncorruted image\n",
    "            except (IOError, SyntaxError) as e:\n",
    "               # print('Bad file:', fp_to_test) # Print out the names of corrupt files\n",
    "                bad_fp_list.append(fp_to_test) # Add bad filepaths to bad_filepath_list\n",
    "                bad_file_list.append(fn) # Add bad files to bad_file_list\n",
    "                stepCompleted = False\n",
    "        #metadata_cache['valid_filenames_all']['MD662']\n",
    "        \n",
    "        if stepCompleted:\n",
    "            print 'Step '+stepStr+' completed!'\n",
    "            print 'done in', time.time() - t, 'seconds' \n",
    "            print ''\n",
    "        else:\n",
    "            print '*****     Bad files found!     *****\\n'\n",
    "            print 'Step '+stepStr+' NOT complete. Rerun necessary parts of the code'\n",
    "            print '`bad_fp_list` and `bad_file_list` created, each contain info on each incomplete files.'\n",
    "            print 'done in', time.time() - t, 'seconds' \n",
    "            print ''\n",
    "            if stepDic[stepStr][0] is None:\n",
    "                print '`'+stack+'_'+stepDic[stepStr][1]+'_'+\\\n",
    "                        stepDic[stepStr][2]+'` was not generated properly'\n",
    "            else:\n",
    "                print '`'+stack+'_prep'+str(stepDic[stepStr][0])+'_'+stepDic[stepStr][1]+'_'+\\\n",
    "                        stepDic[stepStr][2]+'` was not generated properly'\n",
    "            break\n",
    "            #continue\n",
    "    return bad_fp_list, bad_file_list\n",
    "\n",
    "#print where_am_i.__doc__\n",
    "[bad_fp_list, bad_file_list] = where_am_i()\n",
    "\n",
    "print len(bad_file_list),' bad files'\n",
    "print 'bad_fp_list and bad_file_list contain all of the problematic file names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify raw file locations\n",
    "\n",
    "# replaces running \"initialize.py <input_spec_filepath>\"\n",
    "\n",
    "# The set of dirs where we should search for image files.\n",
    "raw_data_dirs = \\\n",
    "{(None, 'raw'): '/media/alexn/BstemAtlasDataBackup/MD662/',\n",
    "(None, 'down32'): '/media/alexn/BstemAtlasDataBackup/MD662/'}\n",
    "\n",
    "# Specifies how to extract image name from file path.\n",
    "# The first group returned by re.search is image_name.\n",
    "input_image_filename_to_imagename_re_pattern_mapping = \\\n",
    "{(None, 'raw'): \\\n",
    " '/media/alexn/BstemAtlasDataBackup/MD662/(.*)_lossless.jp2',\n",
    " (None, 'down32'): \\\n",
    "  '/media/alexn/BstemAtlasDataBackup/MD662/(.*).png', # Check raw data, may NOT be a .png file\n",
    "}\n",
    "\n",
    "# Check that every raw file has all 3 channels properly\n",
    "image_names_all_data_dirs_flattened = set([])\n",
    "image_names_all_data_dirs = {}\n",
    "for vr, data_dir in raw_data_dirs.iteritems():\n",
    "    if data_dir is None: continue\n",
    "    image_names = set([])\n",
    "    if vr in input_image_filename_to_imagename_re_pattern_mapping:\n",
    "        for fn in os.listdir(data_dir):\n",
    "            g = re.search(input_image_filename_to_imagename_re_pattern_mapping[vr], os.path.join(data_dir, fn))\n",
    "            if g is not None:\n",
    "                img_name = g.groups()[0]\n",
    "                image_names.add(img_name)\n",
    "                image_names_all_data_dirs_flattened.add(img_name)\n",
    "    image_names_all_data_dirs[vr] = image_names\n",
    "    \n",
    "# Make sure the every image has all three channels.\n",
    "for vr, img_names in image_names_all_data_dirs.iteritems():\n",
    "    print vr, 'missing:'\n",
    "    print image_names_all_data_dirs_flattened - img_names\n",
    "    print \n",
    "    \n",
    "# set([]) == Good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other instructions \n",
    "- You need to specify in metadata.py relevant filepaths. You need to set certain environment variables. User will need to specify stack name as well.\n",
    "- If thumbnails (downsampled 32x) aren't provided run: resize.py [in_fp_map] [out_fp_map] 0.03125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify input filepaths [From User Guide]\n",
    "Create a JSON file that describes the image file paths as described in preprocessing.md: https://github.com/ActiveBrainAtlas/MouseBrainAtlas/blob/master/doc/User%20Manuals/user_guide_pages/Preprocessing.md\n",
    "\n",
    "Then run `initialize.py <input_spec_filepath>`\n",
    "\n",
    "thumbnail_NtbNormalized ->\n",
    "\n",
    "                 -> <stack>_sorted_filenames.txt\n",
    " \n",
    "                 -> <stack>_thumbnail_Ntb/\n",
    " \n",
    "                 -> <stack>_raw_Ntb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1\n",
    "### raw (.jp2) -> raw_Ntb (.tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_dir = '/media/alexn/BstemAtlasDataBackup/MD662/'\n",
    "output_dir = create_if_not_exists(DataManager.get_image_dir_v2(stack=stack, prep_id=None, resol='raw'))\n",
    "\n",
    "# INPUT TEST\n",
    "in_list = [os.path.join(in_dir, img_name + '_lossless.jp2') \n",
    "                                       for img_name in list(image_names_all_data_dirs_flattened)]\n",
    "# OUTPUT TEST\n",
    "out_list = [DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \n",
    "                                        resol='raw', version=None, fn=img_name) \n",
    "                                        for img_name in list(image_names_all_data_dirs_flattened)]\n",
    "\n",
    "print('first input file: ',in_list[0])\n",
    "print('first output file: ',out_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multiple core processing on every individual file (takes about 4 minutes each)\n",
    "# In total will take about 30 hours\n",
    "# Creates new files at /CSHL_data_processed/MD662/MD662_raw/*_raw.tif\n",
    "t = time.time()\n",
    "\n",
    "run_distributed('export LD_LIBRARY_PATH=%(kdu_dir)s:$LD_LIBRARY_PATH; %(kdu_bin)s -i \\\"%%(in_fp)s\\\" -o \\\"%%(out_fp)s\\\"' % \\\n",
    "                {'kdu_bin': KDU_EXPAND_BIN, 'kdu_dir': os.path.dirname(KDU_EXPAND_BIN)},\n",
    "                kwargs_list={'in_fp': [os.path.join(in_dir, img_name + '_lossless.jp2') \n",
    "                                       for img_name in list(image_names_all_data_dirs_flattened)], \n",
    "                             'out_fp': [DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \n",
    "                                        resol='raw', version=None, fn=img_name) \n",
    "                                        for img_name in list(image_names_all_data_dirs_flattened)]},\n",
    "                argument_type='single',\n",
    "                jobs_per_node=1, # Use single process\n",
    "                local_only=True, # Run local\n",
    "                use_aws=False)   # Run local\n",
    "print 'done in', time.time() - t, 'seconds' # 2252 seconds full stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2\n",
    "### raw_Ntb -> thumbnail_Ntb\n",
    "rescale\n",
    "\n",
    "# & STEP 3\n",
    "### thumbnail_Ntb -> thumbnail_NtbNormalized\n",
    "normalize_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_if_not_exists(DataManager.get_image_dir_v2(stack=stack, prep_id=None, resol='raw', version='Ntb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw -> raw_Ntb\n",
    "# Multiple core processing on every individual file (takes about 4 minutes each)\n",
    "# In total will take about 20 hours\n",
    "# Creates new files at CSHL_data_processed/MD662/MD662_raw_Ntb/*_raw_Ntb.tif\n",
    "t = time.time()\n",
    "run_distributed('convert \\\"%(in_fp)s\\\" -channel B -separate \\\"%(out_fp)s\\\"',\n",
    "                kwargs_list={'in_fp': [DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \n",
    "                                        resol='raw', version=None, fn=img_name) \n",
    "                                       for img_name in list(image_names_all_data_dirs_flattened)], \n",
    "                             'out_fp': [DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \n",
    "                                        resol='raw', version='Ntb', fn=img_name) \n",
    "                                        for img_name in list(image_names_all_data_dirs_flattened)]},\n",
    "                argument_type='single',\n",
    "                jobs_per_node=1,\n",
    "                local_only=True,\n",
    "               use_aws=False)\n",
    "print('finished generating raw_Ntb files')\n",
    "print 'done in', time.time() - t, 'seconds' # 2252 seconds full stack\n",
    "\n",
    "thumbnail_downscale_factor = 32\n",
    "tb_resol = 'thumbnail'\n",
    "\n",
    "# Takes about 1 minute per file, in total about 8-10 hours\n",
    "\n",
    "# Will create new files at the filepaths /CSHL_data_processed/MD662/MD662_thumbnail_Ntb/*_thumbnail_Ntb.tif\n",
    "#  and /CSHL_data_processed/MD662/MD662_thumbnail_NtbNormalized/*_thumbnail_NtbNormalized.tif\n",
    "# Only 108 files in each directory though?\n",
    "i = 0\n",
    "\n",
    "for img_name in metadata_cache['valid_filenames_all'][stack]:\n",
    "    i = i+1\n",
    "    print '\\n\\n'+img_name+'\\n'\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    in_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, resol='raw', version='Ntb', \\\n",
    "                                              fn=img_name)\n",
    "    out_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, resol=tb_resol, version='Ntb', \\\n",
    "                                              fn=img_name)\n",
    "    create_parent_dir_if_not_exists(out_fp)\n",
    "    \n",
    "  #  if os.path.isfile(out_fp):\n",
    "  #      print('SKIPPING NeurotraceB: '+out_fp)\n",
    "  #      #continue\n",
    "  #  else:\n",
    "    \n",
    "    try:\n",
    "        img = imread(in_fp)\n",
    "    except IndexError:\n",
    "        print('Problematic file detected\\n\\n'+out_fp+'\\n\\n')\n",
    "        \n",
    "    print(out_fp)\n",
    "    img_tb = img[::thumbnail_downscale_factor, ::thumbnail_downscale_factor]\n",
    "    imsave(out_fp, img_tb)\n",
    "    \n",
    "    \n",
    "    # Alternative: ImageMagick introduces an artificial noisy stripe in the output image.\n",
    "#     cmd = 'convert %(in_fp)s -scale 3.125%% %(out_fp)s' % {'in_fp': in_fp, 'out_fp': out_fp}\n",
    "#     execute_command(cmd)\n",
    "        \n",
    "    sys.stderr.write(\"Rescale: %.2f seconds.\\n\" % (time.time() - t)) # ~20s / image\n",
    "    \n",
    "    t = time.time()\n",
    "\n",
    "    in_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, resol=tb_resol, version='Ntb', \\\n",
    "                                              fn=img_name)\n",
    "    out_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, resol=tb_resol, version='NtbNormalized',\\\n",
    "                                               fn=img_name)\n",
    "    create_parent_dir_if_not_exists(out_fp)\n",
    "    \n",
    "  #  if os.path.isfile(out_fp):\n",
    "  #      print('SKIPPING Ntb Normalized: '+out_fp)\n",
    "  #      continue\n",
    "  #  else:\n",
    "    print(out_fp)\n",
    "    cmd = \"\"\"convert \"%(in_fp)s\" -normalize -depth 8 \"%(out_fp)s\" \"\"\" % {'in_fp': in_fp, 'out_fp': out_fp}\n",
    "    execute_command(cmd)\n",
    "  #  try:\n",
    "  #      img = imread(in_fp)\n",
    "  #  except IndexError:\n",
    "  #      print('Problematic file detected\\n\\n'+out_fp+'\\n\\n')\n",
    "    \n",
    "    \n",
    "    sys.stderr.write(\"Intensity normalize: %.2f seconds.\\n\" % (time.time() - t))\n",
    "print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4\n",
    "### Compute transforms using thumbnail_NtbNormalized\n",
    "align + compose\n",
    "\n",
    "#### Generally how it works:\n",
    "- Generate Elastix output from thumbnail_NtbNormalized\n",
    "    - These are pairwise transformations for the files\n",
    "        - Saved in /elastix_output/\n",
    "    - Roughly 3% will fail and will need to be run through. Use GUI to fix\n",
    "        - Saved in /custom_transform/\n",
    "- Select an anchor file to unite all pairwise transformations\n",
    "    - /gui/preprocess_tool_v3.py\n",
    "        - Anchor.txt is created with name of anchor file\n",
    "    - Transformation matrices generated for each file relative to anchor\n",
    "        - Saved in transformTo_[anchorName].pkl\n",
    "    - Generate /prep1_thumbnail_normalized/ images. May be padded with white\n",
    "        - prep1_thumbnail_normalized files used as inputs to \"Active Contour Algorithm\" \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack, redownload=True) \n",
    "\n",
    "tb_fmt = 'tif'\n",
    "version = 'NtbNormalized'\n",
    "valid_filenames = metadata_cache['valid_filenames_all'][stack]\n",
    "# Note that this could be the human-corrected version, in which case the transforms may not exist.\n",
    "valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "\n",
    "script = os.path.join(REPO_DIR, 'preprocess', 'align_consecutive_v2.py')\n",
    "input_dir = DataManager.get_image_dir_v2(stack=stack, prep_id=None, version=version, resol='thumbnail')    \n",
    "output_dir = create_if_not_exists(os.path.join(THUMBNAIL_DATA_DIR, stack, stack + '_elastix_output'))\n",
    "print('Input: ',input_dir)\n",
    "print('Output: ',output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "print 'Align...'\n",
    "\n",
    "run_distributed(\"%(script)s %(stack)s \\\"%(input_dir)s\\\" \\\"%(output_dir)s\\\" \\'%%(kwargs_str)s\\' %(fmt)s -p \\\n",
    "%(param_fp)s -r\" % \\\n",
    "                {'script': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir,\n",
    "                'fmt': tb_fmt,\n",
    "                 'param_fp': '/home/yuncong/Brain/preprocess/parameters/Parameters_Rigid_MutualInfo_noNumberOfSpatialSamples_4000Iters.txt'\n",
    "                },\n",
    "                kwargs_list=[{'prev_fn': valid_filenames[i-1] + '_thumbnail_' + version, \n",
    "                              'curr_fn': valid_filenames[i] + '_thumbnail_' + version,\n",
    "                             'prev_sn': valid_filenames[i-1] ,\n",
    "                             'curr_sn': valid_filenames[i] } \n",
    "                             for i in range(1, len(valid_filenames))],\n",
    "                argument_type='list',\n",
    "                jobs_per_node=8,\n",
    "               local_only=True)\n",
    "\n",
    "# wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 2252 seconds full stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN GUI TO CHECK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5\n",
    "### Supply prep1_thumbnail_mask \n",
    "^ Need to clarify with Yuncong HOW to do this\n",
    "\n",
    "#### Also compose alignments\n",
    "-> [stackName]_transformsTo_[anchorFilename].pkl\n",
    "\n",
    "thumbnail_NtbNormalized ->\n",
    "[stackName]\\_transformsTo\\_[anchorFilename].pkl -> prep1_thumbnail_NtbNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-87085713460d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manchor_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_anchor_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0manchor_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_filenames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'anchor_idx ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREPO_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'preprocess'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'compose_transform_thumbnail_v2.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataManager' is not defined"
     ]
    }
   ],
   "source": [
    "anchor_fn = DataManager.load_anchor_filename(stack=stack)\n",
    "anchor_idx = valid_filenames.index(anchor_fn)\n",
    "print 'anchor_idx =', anchor_idx\n",
    "\n",
    "script = os.path.join(REPO_DIR, 'preprocess', 'compose_transform_thumbnail_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_elastix_output')\n",
    "output_fp = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_%(anchor_fn)s.pkl' % \\\n",
    "                         dict(stack=stack, anchor_fn=anchor_fn))\n",
    "\n",
    "print('Script: ',script,'\\n')\n",
    "print('Input: ',input_dir)\n",
    "print('Output: ',output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -> [stackName]_transformsTo_[anchorFilename].pkl\n",
    "t = time.time()\n",
    "print 'Composing transform...'\n",
    "\n",
    "run_distributed(\"%(script)s %(stack)s \\\"%(input_dir)s\\\" \\'%%(kwargs_str)s\\' %(anchor_idx)d \\\"%(output_fp)s\\\"\" % \\\n",
    "            {'stack': stack,\n",
    "            'script': script,\n",
    "            'input_dir': input_dir,\n",
    "            'anchor_idx': anchor_idx,\n",
    "            'output_fp': output_fp},\n",
    "            kwargs_list=[{'filenames': metadata_cache['valid_filenames_all'][stack]}],\n",
    "            argument_type='list',\n",
    "               local_only=True)\n",
    "\n",
    "# wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "print 'Warping...'\n",
    "\n",
    "transforms_to_anchor = DataManager.load_transforms(stack=stack, downsample_factor=32, \\\n",
    "                                                   use_inverse=False, anchor_fn=anchor_fn)\n",
    "# useful for alternatively stained stacks where bg varies depending on stain on each section\n",
    "if pad_bg_color == 'auto': \n",
    "    run_distributed('%(script)s %(stack)s \\\"%%(input_fp)s\\\" \\\"%%(output_fp)s\\\" %%(transform)s \\\n",
    "    thumbnail 0 0 2000 1500 %%(pad_bg_color)s' % \\\n",
    "                    {'script': script,\n",
    "                    'stack': stack,\n",
    "                    },\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                                'input_fp': DataManager.get_image_filepath_v2(stack=stack, fn=fn, \\\n",
    "                                                            prep_id=None, version=version, resol='thumbnail'),\n",
    "                                  'output_fp': DataManager.get_image_filepath_v2(stack=stack, fn=fn,\\\n",
    "                                                            prep_id=prep_id, version=version, resol='thumbnail'),\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                                for fn in metadata_cache['valid_filenames_all'][stack]],\n",
    "                    argument_type='single',\n",
    "                   jobs_per_node=8,\n",
    "                   local_only=True)\n",
    "else:\n",
    "    run_distributed('%(script)s %(stack)s \\\"%%(input_fp)s\\\" \\\"%%(output_fp)s\\\" %%(transform)s \\\n",
    "    thumbnail 0 0 2000 1500 %(pad_bg_color)s' % \\\n",
    "                    {'script': script,\n",
    "                    'stack': stack,\n",
    "                    'pad_bg_color': pad_bg_color},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                                'input_fp': DataManager.get_image_filepath_v2(stack=stack, fn=fn, \\\n",
    "                                                            prep_id=None, version=version, resol='thumbnail'),\n",
    "                                  'output_fp': DataManager.get_image_filepath_v2(stack=stack, fn=fn, \\\n",
    "                                                            prep_id=prep_id, version=version, resol='thumbnail'),\n",
    "                                 }\n",
    "                                for fn in metadata_cache['valid_filenames_all'][stack]],\n",
    "                    argument_type='single',\n",
    "                   jobs_per_node=8,\n",
    "                   local_only=True)\n",
    "\n",
    "# wait_qsub_complete()\n",
    "    \n",
    "print 'done in', time.time() - t, 'seconds' # 300 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6\n",
    "### prep1_thumbnail_mask -> thumbnail_mask\n",
    "warp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[\n",
    "### Next step is to run the \"Active Conour Algorithm\", the mask generation step.\n",
    "prep1_thumbnail_normalized -> prep1_thumbnail_mask\n",
    "### For now, I am skipping this step. Y suggested I download masks from S3 directly and skip to the alignment process.\n",
    "Skipping Mask Generation. Downloading masks.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_from_s3(os.path.join('CSHL_data_processed', stack, stack + '_prep1_thumbnail_mask'), \n",
    "                 is_dir=True, local_root=DATA_ROOTDIR, redownload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 7\n",
    "### raw_Ntb -> raw_NtbNormalizedAdaptiveInvertedGamma\n",
    "brightness_correction\n",
    "\n",
    "(Requires *_raw_normalizedFloatMap.bp' for each file)\n",
    "generate raw_mask -> generate STACK_intensity_normalization_results/normalizedFloatMap/ files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity, adjust_gamma\n",
    "\n",
    "# Generates the raw_mask\n",
    "for section in metadata_cache['valid_sections_all'][stack]:\n",
    "    \n",
    "    print \"Section\", section\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    img = DataManager.load_image_v2(stack=stack, prep_id=None, section=section, version='Ntb', resol='raw')\n",
    "\n",
    "    sys.stderr.write('Load image: %.2f seconds.\\n' % (time.time() - t))\n",
    "\n",
    "    t = time.time()\n",
    "    tb_mask = DataManager.load_thumbnail_mask_v3(stack=stack, prep_id=None, section=section)\n",
    "#     raw_mask = rescale_by_resampling(tb_mask, new_shape=(img.shape[1], img.shape[0]))\n",
    "    raw_mask = resize(tb_mask, img.shape) > .5\n",
    "    \n",
    "    save_data(raw_mask, \n",
    "          DataManager.get_image_filepath_v2(stack=stack, prep_id=None, section=section, version='mask', resol='raw', ext='bp'), \n",
    "          upload_s3=False)\n",
    "    \n",
    "    sys.stderr.write('Rescale mask: %.2f seconds.\\n' % (time.time() - t))\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    mean_std_all_regions = []\n",
    "    cx_cy_all_regions = []\n",
    "    region_size = 5000\n",
    "    region_spacing = 3000\n",
    "    for cx in range(0, img.shape[1], region_spacing):\n",
    "        for cy in range(0, img.shape[0], region_spacing):\n",
    "            region = img[max(cy-region_size/2, 0):min(cy+region_size/2+1, img.shape[0]-1), \n",
    "                         max(cx-region_size/2, 0):min(cx+region_size/2+1, img.shape[1]-1)]\n",
    "            region_mask = raw_mask[max(cy-region_size/2, 0):min(cy+region_size/2+1, img.shape[0]-1), \n",
    "                                   max(cx-region_size/2, 0):min(cx+region_size/2+1, img.shape[1]-1)]\n",
    "            if np.count_nonzero(region_mask) == 0:\n",
    "                continue\n",
    "            mean_std_all_regions.append((region[region_mask].mean(), region[region_mask].std()))\n",
    "            cx_cy_all_regions.append((cx, cy))\n",
    "            \n",
    "    sys.stderr.write('Compute mean/std for sample regions: %.2f seconds.\\n' % (time.time() - t))\n",
    "    \n",
    "    t = time.time()\n",
    "    mean_map = resample_scoremap(sparse_scores=np.array(mean_std_all_regions)[:,0], \n",
    "                             sample_locations=cx_cy_all_regions,\n",
    "                             gridspec=(region_size, region_spacing, img.shape[1], img.shape[0], (0,0)),\n",
    "                            downscale=4, \n",
    "                                 interpolation_order=2)\n",
    "\n",
    "    sys.stderr.write('Interpolate mean map: %.2f seconds.\\n' % (time.time() - t)) #10s\n",
    "\n",
    "    t = time.time()\n",
    "    mean_map = rescale_by_resampling(mean_map, new_shape=(img.shape[1], img.shape[0]))\n",
    "    sys.stderr.write('Scale up mean map: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "\n",
    "    t = time.time()\n",
    "    std_map = resample_scoremap(sparse_scores=np.array(mean_std_all_regions)[:,1], \n",
    "                             sample_locations=cx_cy_all_regions,\n",
    "                             gridspec=(region_size, region_spacing, img.shape[1], img.shape[0], (0,0)),\n",
    "                            downscale=4,\n",
    "                               interpolation_order=2)\n",
    "    sys.stderr.write('Interpolate std map: %.2f seconds.\\n' % (time.time() - t)) #10s\n",
    "\n",
    "    t = time.time()\n",
    "    std_map = rescale_by_resampling(std_map, new_shape=(img.shape[1], img.shape[0]))\n",
    "    sys.stderr.write('Scale up std map: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "    \n",
    "    # Save mean/std results.\n",
    "    \n",
    "    fp = DataManager.get_intensity_normalization_result_filepath(what='region_centers', stack=stack, section=section)\n",
    "    create_parent_dir_if_not_exists(fp)    \n",
    "    np.savetxt(fp, cx_cy_all_regions)\n",
    "    \n",
    "    fp = DataManager.get_intensity_normalization_result_filepath(what='mean_std_all_regions', stack=stack, section=section)\n",
    "    create_parent_dir_if_not_exists(fp)\n",
    "    np.savetxt(fp, mean_std_all_regions)\n",
    "    \n",
    "    fp = DataManager.get_intensity_normalization_result_filepath(what='mean_map', stack=stack, section=section)\n",
    "    create_parent_dir_if_not_exists(fp)\n",
    "    bp.pack_ndarray_file(mean_map.astype(np.float16), fp)\n",
    "    \n",
    "    fp = DataManager.get_intensity_normalization_result_filepath(what='std_map', stack=stack, section=section)\n",
    "    create_parent_dir_if_not_exists(fp)\n",
    "    bp.pack_ndarray_file(std_map.astype(np.float16), fp)\n",
    "\n",
    "    # Export normalized image.\n",
    "    \n",
    "    t = time.time()\n",
    "    raw_mask = raw_mask & (std_map > 0)\n",
    "    img_normalized = np.zeros(img.shape, np.float32)\n",
    "    img_normalized[raw_mask] = (img[raw_mask] - mean_map[raw_mask]) / std_map[raw_mask]\n",
    "    sys.stderr.write('Normalize: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "\n",
    "    t = time.time()\n",
    "    # FIX THIS! THIS only save uint16, not float16. Need to save as bp instead.\n",
    "#     img_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \\\n",
    "#version='NtbNormalizedFloat', resol='down8', section=section, )\n",
    "#     create_parent_dir_if_not_exists(img_fp)\n",
    "#     imsave(img_fp, img_normalized[::8, ::8].astype(np.float16))\n",
    "    save_data(img_normalized.astype(np.float16), \n",
    "              DataManager.get_intensity_normalization_result_filepath(what='normalized_float_map', stack=stack, section=section),\n",
    "             upload_s3=False)\n",
    "    sys.stderr.write('Save float version: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "    \n",
    "    \n",
    "    # Export histogram.\n",
    "    \n",
    "    plt.hist(img_normalized[raw_mask].flatten(), bins=100, log=True);\n",
    "    fp = DataManager.get_intensity_normalization_result_filepath(what='float_histogram_png', stack=stack, section=section)\n",
    "    create_parent_dir_if_not_exists(fp)\n",
    "    plt.savefig(fp)\n",
    "    plt.close();\n",
    "    \n",
    "#     hist_fp = DataManager.get_intensity_normalization_result_filepath(what='float_histogram', stack=stack, section=section)\n",
    "#     create_parent_dir_if_not_exists(hist_fp)\n",
    "    \n",
    "#     hist, bin_edges = np.histogram(img_normalized[valid_mask].flatten(), bins=np.arange(0,201,5));\n",
    "\n",
    "#     plt.bar(bin_edges[:-1], np.log(hist));\n",
    "#     plt.xticks(np.arange(0, 200, 20), np.arange(0, 200, 20));\n",
    "#     plt.xlabel('Normalized pixel value (float)');\n",
    "#     plt.title(metadata_cache['sections_to_filenames'][stack][section])\n",
    "\n",
    "#     plt.savefig(hist_fp)\n",
    "#     plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5-10 seconds per section\n",
    "for section in metadata_cache['valid_sections_all'][stack]:\n",
    "        \n",
    "    print section\n",
    "    \n",
    "    raw_mask = load_data(DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \\\n",
    "                                     section=section, version='mask', resol='raw', ext='bp'),download_s3=False)\n",
    "    \n",
    "    img_normalized = load_data(\n",
    "              DataManager.get_intensity_normalization_result_filepath(what='normalized_float_map', \\\n",
    "                                     stack=stack, section=section), download_s3=False)\n",
    "        \n",
    "    q = img_normalized[raw_mask]\n",
    "    \n",
    "    save_data(np.percentile(q, range(101)), \n",
    "              DataManager.get_intensity_normalization_result_filepath(what='float_percentiles', \\\n",
    "                                                    stack=stack, section=section), upload_s3=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma_map = img_as_ubyte(adjust_gamma(np.arange(0, 256, 1) / 255., 8.))\n",
    "# 10-30 seconds per section\n",
    "for section in metadata_cache['valid_sections_all'][stack]:\n",
    "\n",
    "    print section\n",
    "    \n",
    "    img_normalized = load_data(\n",
    "              DataManager.get_intensity_normalization_result_filepath(what='normalized_float_map', \\\n",
    "                                                        stack=stack, section=section), download_s3=False)\n",
    "        \n",
    "    t = time.time()\n",
    "    img_normalized_uint8 = rescale_intensity_v2(img_normalized, -2., 50.)\n",
    "    sys.stderr.write('Rescale to uint8: %.2f seconds.\\n' % (time.time() - t))\n",
    "\n",
    "    t = time.time()\n",
    "    raw_mask = load_data(DataManager.get_image_filepath_v2(stack=stack, prep_id=None, section=section, \\\n",
    "                                                    version='mask', resol='raw', ext='bp'), download_s3=False)\n",
    "    img_normalized_uint8[~raw_mask] = 0\n",
    "    sys.stderr.write('Load mask: %.2f seconds.\\n' % (time.time() - t))\n",
    "    \n",
    "#     t = time.time()\n",
    "#     save_data(img_normalized_uint8, DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \\\n",
    "#section=section, version='NtbNormalizedAdaptive', resol='raw'),\n",
    "#              upload_s3=False)\n",
    "#     sys.stderr.write('Save uint8 version: %.2f seconds.\\n' % (time.time() - t))\n",
    "    \n",
    "#     img_normalized_uint8 = \\\n",
    "#     DataManager.load_image_v2(stack=stack, prep_id=None, section=section, version='NtbNormalizedAdaptive',\\\n",
    "#resol='raw')\n",
    "    img = 255 - img_normalized_uint8\n",
    "    save_data(gamma_map[img], \n",
    "              DataManager.get_image_filepath_v2(stack=stack, prep_id=None, section=section, \\\n",
    "                                    version='NtbNormalizedAdaptiveInvertedGamma', resol='raw'), upload_s3=False)\n",
    "# outputs the *_raw_NtbNormalizedAdaptiveInvertedGamma files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 8\n",
    "### prep1 -> prep5\n",
    "Compute prep5 (alignedWithMargin) cropping box based on prep1_thumbnail_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 9\n",
    "### raw_NtbNormalizedAdaptiveInvertedGamma -> prep5_raw_NtbNormalizedAdaptiveInvertedGamma\n",
    "align + crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# roughly 1 second per slice\n",
    "# Generates *_prep5_raw_NtbNormalizedAdaptiveInvertedGamma\n",
    "for stack in ['MD662']:\n",
    "\n",
    "    alignedWithMargin_xmin, alignedWithMargin_xmax,\\\n",
    "    alignedWithMargin_ymin, alignedWithMargin_ymax = DataManager.load_cropbox_v2(stack=stack, anchor_fn=None, \n",
    "                                                            prep_id='alignedWithMargin',\n",
    "                                                           return_dict=False, only_2d=True)\n",
    "            \n",
    "    for section in metadata_cache['valid_sections_all'][stack]:\n",
    "        \n",
    "        for version in ['NtbNormalized']:\n",
    "#         for version in [None, 'mask']:\n",
    "\n",
    "            in_fp = DataManager.get_image_filepath_v2(\\\n",
    "                                stack=stack, prep_id=1, section=section, version=version, resol='thumbnail')\n",
    "\n",
    "            out_fp = DataManager.get_image_filepath_v2(\\\n",
    "                                stack=stack, prep_id=5, section=section, version=version, resol='thumbnail')\n",
    "\n",
    "            create_parent_dir_if_not_exists(out_fp)\n",
    "\n",
    "            t = time.time()\n",
    "\n",
    "            im_prep1 = imread(in_fp)\n",
    "            im_prep5 = im_prep1[alignedWithMargin_ymin:alignedWithMargin_ymax+1, \n",
    "                                alignedWithMargin_xmin:alignedWithMargin_xmax+1]        \n",
    "            save_data(im_prep5, out_fp)\n",
    "            \n",
    "            sys.stderr.write('Generate prep5: %.2f seconds.\\n' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 10\n",
    "### thumbnail_NtbNormalized -> prep5_thumbnail_NtbNormalized\n",
    "align + crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 11\n",
    "### prep5_raw_NtbNormalizedAdaptiveInvertedGamma -> prep5_thumbnail_NtbNormalizedAdaptiveInvertedGamma\n",
    "rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 12\n",
    "### Specify prep2 (alignedBrainstemCrop) cropping box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 13\n",
    "### prep5_raw_NtbNormalizedAdaptiveInvertedGamma -> prep2_raw_NtbNormalizedAdaptiveInvertedGamma\n",
    "crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 14\n",
    "### prep2_raw_NtbNormalizedAdaptiveInvertedGamma -> prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg\n",
    "compress_jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
